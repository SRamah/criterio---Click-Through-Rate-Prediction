{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDRegressor,SGDClassifier\n",
    "import zipfile\n",
    "import tarfile\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from OneHotEncoderPartial import OneHotEncoder\n",
    "\n",
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "from sklearn.utils import murmurhash3_32\n",
    "\n",
    "import sys, traceback\n",
    "import copy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def DumpObject(name, Object):\n",
    "    # enregistrement ...\n",
    "    with open(name, 'wb') as fichier:\n",
    "        mon_pickler = pickle.Pickler(fichier)\n",
    "        mon_pickler.dump(Object)\n",
    "\n",
    "def LoadObject(name):\n",
    "    # Lecture des objets contenus dans le fichier...\n",
    "    with open(name, 'rb') as fichier:\n",
    "        mon_depickler = pickle.Unpickler(fichier)\n",
    "        object_recupere = mon_depickler.load()\n",
    "    return object_recupere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanNull(DF):\n",
    "    for column in DF.columns.values:\n",
    "        replace = DF[column].value_counts()\n",
    "        index_min = np.argmin(replace)\n",
    "        DF[column].fillna(index_min , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateFeatureEngine(DF , toGenerate):\n",
    "    for g in toGenerate :\n",
    "        for i in toGenerate :\n",
    "            if i != g :\n",
    "                newName = str(g) + \":\" + str(i)\n",
    "                DF[newName] = newName+DF[i].astype('str')+\":\"+DF[g].astype('str')\n",
    "                #print newName\n",
    "                for j in toGenerate :\n",
    "                    if j!= i and j!=g :\n",
    "                        newX = newName + \":\" + str(j)\n",
    "                        DF[newX] = newX+DF[newName]+\":\"+DF[j].astype('str')\n",
    "                        #print newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNameCols():\n",
    "    num_Cols=[]\n",
    "    cat_Cols = []\n",
    "    dd = {}\n",
    "    dd[0]=\"Label\"\n",
    "    for i in range(1,14):\n",
    "        dd[i]=\"I\"+`i`\n",
    "        num_Cols.append(\"I\"+`i`)\n",
    "    for c in range(1,27):\n",
    "        dd[c+13]=\"C\"+`c`\n",
    "        cat_Cols.append(\"C\"+`c`)\n",
    "    \n",
    "    return dd, num_Cols, cat_Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PrepareData(DF, FutureEngineering):\n",
    "    dd, num_Cols, cat_Cols = getNameCols()\n",
    "    DF.rename(columns=dd, inplace=True)\n",
    "    #cleanNull(DF)\n",
    "    generateFeatureEngine(DF, FutureEngineering[:3])\n",
    "    return np.array(DF, dtype='str'), DF.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-17), 10e-17)        # The bounds\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_direct_x(csv_row, header, D):\n",
    "    fullind = []\n",
    "    x = {}\n",
    "    for key in range(1,len(header)):\n",
    "        s = header[key] + '=' + str(csv_row[key])\n",
    "        fullind.append(murmurhash3_32(s, positive=True) % D)\n",
    "           \n",
    "    x[0] = 1  # 0 is the index of the bias term\n",
    "    for index in fullind:\n",
    "        if(not x.has_key(index)):\n",
    "            x[index] = 0\n",
    "        x[index] += 1\n",
    "        \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob(x, w):\n",
    "    wTx = 0.\n",
    "    for i, xi in x.items():\n",
    "        wTx += w[i] * xi  # w[i] * x[i]\n",
    "        \n",
    "    return 1. / (1. + exp(-max(min(wTx, 50.), -50.)))  # bounded sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, g, x, p, y, alpha):\n",
    "    for i, xi in x.items():\n",
    "        g[i] += 1\n",
    "        w[i] -= (p - y) * xi * alpha / (sqrt(g[i]))  # Minimising log loss\n",
    "    return w, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parametres(alpha, batch_size, D):\n",
    "    return alpha, batch_size, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training(df, FutureEngineering, separator, alpha, batch_size, D, w, g, score_liste, ti, LoadBack):\n",
    "    alpha, batch_size, D = parametres(alpha, batch_size, D)\n",
    "    ter=0\n",
    "    # initialize our model\n",
    "    if LoadBack :\n",
    "        ter = LoadObject(\"settings/last_index\")\n",
    "        index_verification = LoadObject(\"settings/index_\"+`(ter-1)/batch_size`)\n",
    "        #Check index\n",
    "        if ter==index_verification:\n",
    "            w = LoadObject(\"settings/weights_\"+`(ter-1)/batch_size`)\n",
    "            g = LoadObject(\"settings/gradients_\"+`(ter-1)/batch_size`)\n",
    "            scores = LoadObject(\"settings/score_liste_\"+`(ter-1)/batch_size`)\n",
    "            loss=scores[-1]\n",
    "        else:\n",
    "            sys.exit(\"last_index (\"+`t`+\") != index_\"+`(t-1)/batch_size`+\" (\"+index_verification+\")\")\n",
    "    else:\n",
    "        scores = score_liste\n",
    "        loss=scores[-1]\n",
    "        ter = ti\n",
    "    \n",
    "    # start training\n",
    "    lossb = 0.\n",
    "    df_train, header = PrepareData(df, FutureEngineering)\n",
    "    for row in df_train:\n",
    "        y = 1. if row[0] == '1' else 0.\n",
    "\n",
    "        # step 1, get the hashed features\n",
    "        x = get_direct_x(row, header, D)\n",
    "        # step 2, get prediction\n",
    "        p = get_prob(x, w)\n",
    "\n",
    "        # for progress validation, useless for learning our model\n",
    "        lossx = logloss(p, y)\n",
    "        loss += lossx\n",
    "        lossb += lossx\n",
    "        if (ter % batch_size == 0 and ter > 1):\n",
    "            print('\\t Line : %d\\t logloss: %f\\t batch logloss: %f' % ( ter, loss/ter,  lossb/batch_size))\n",
    "            lossb = 0.\n",
    "            score_liste.append(loss)\n",
    "        elif ter==len(df_train):\n",
    "            print('\\t Line : %d\\t logloss: %f\\t batch logloss: %f \\n' % ( ter, loss/ter,  lossb/(ter%batch_size)))\n",
    "            lossb = 0.\n",
    "            score_liste.append(loss)\n",
    "\n",
    "        # step 3, update model with answer\n",
    "        w, g = update_w(w, g, x, p, y, alpha)\n",
    "        ter+=1\n",
    "    \n",
    "    return w, g, scores, ter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainAll(extractfile, FutureEngineering, chunksize, separator, alpha, batch_size, D, LoadBack):\n",
    "    # initialize our model\n",
    "    weights = [0.] * D  # weights\n",
    "    gradients = [.5] * D  # sum of historical gradients\n",
    "    scores_liste = [0]\n",
    "    tr=1\n",
    "    extractfile.seek(0)\n",
    "    for chunk in pd.read_csv(extractfile, chunksize=chunksize, header=-1, sep=separator):\n",
    "        print \"\\ntraining ...\",(tr-1.0)/chunksize+1.0,\"M\"\n",
    "        %time weights, gradients, scores_liste, tr = training(chunk, FutureEngineering, separator, alpha, batch_size, D, weights, gradients, scores_liste, tr, LoadBack)\n",
    "        tr=tr+len(chunk)\n",
    "        #if (tr-1)==3000:\n",
    "        #     break\n",
    "        #Save settings\n",
    "        if LoadBack:\n",
    "            DumpObject(\"settings/weights_\"+`(t-1)/batch_size`, weights)\n",
    "            DumpObject(\"settings/gradients_\"+`(t-1)/batch_size`, gradients)\n",
    "            DumpObject(\"settings/score_liste_\"+`(t-1)/batch_size`, scores_liste)\n",
    "            DumpObject(\"settings/index_\"+`(tr-1)/batch_size`, tr)\n",
    "            DumpObject(\"settings/last_index\", tr)\n",
    "    \n",
    "    \n",
    "    return weights, gradients, scores_liste, tr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Searching(path, chunksize, stopSize ,FutureEngineering, separator, batch_size, D, w, scores_cv):\n",
    "    # initialize our model\n",
    "    loss=0\n",
    "    ter=0\n",
    "    # start CV\n",
    "    for df in pd.read_csv(path, chunksize=chunksize, header=-1, sep=separator):\n",
    "        ter+=len(df)\n",
    "        df_cv, header = PrepareData(df, FutureEngineering)\n",
    "        for row in df_cv:\n",
    "            y = 1. if row[0] == '1' else 0.\n",
    "\n",
    "            # step 1, get the hashed features\n",
    "            x = get_direct_x(row, header, D)\n",
    "            # step 2, get prediction\n",
    "            p = get_prob(x, w)\n",
    "\n",
    "            # for progress validation, useless for learning our model\n",
    "            lossx = logloss(p, y)\n",
    "            loss += lossx\n",
    "        if stopSize<=ter and stopSize>0 :\n",
    "            break\n",
    "        \n",
    "    \n",
    "    scores_cv.append(loss/ter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def searchParametres(extractfile, FutureEngineering, chunksize, separator, alpha, batch_size, D, LoadBack):\n",
    "    print \"\\n_______________________________ \"+`alpha`+\" | \"+`D`+\" _______________________________\\n\"\n",
    "    \n",
    "    stop=4*(10**6)\n",
    "    cv_step=10**5\n",
    "    \n",
    "    # initialize our model\n",
    "    weights = [0.] * D  # weights\n",
    "    gradients = [.25] * D  # sum of historical gradients\n",
    "    scores_liste = [0]\n",
    "    scores_cv = [0]\n",
    "    tr=1\n",
    "    ind=0\n",
    "    extractfile.seek(0)\n",
    "    for chunk in pd.read_csv(extractfile, chunksize=chunksize, header=-1, sep=separator):\n",
    "        ind+=1\n",
    "        print \"\\ntraining ...\",(tr-1.0)/chunksize+1.0,\"M\"\n",
    "        %time weights, gradients, scores_liste, tr = training(chunk, FutureEngineering, separator, alpha, batch_size, D, weights, gradients, scores_liste, tr, LoadBack)\n",
    "        tr=tr+len(chunk)\n",
    "        \"\"\"if (tr-1)==cv_step*ind:\n",
    "            print \"\\n=================================== CV ===========================================\"\n",
    "            %time Searching(\"data/cv.txt\", chunksize, -1, FutureEngineering, separator, batch_size, D, weights, scores_cv)\n",
    "            print \"CV ... \",scores_cv[-1],\"\\n=================================================================================\\n\"\n",
    "        \"\"\"\n",
    "\n",
    "        #Save settings\n",
    "        if (tr-1)==stop:\n",
    "            DumpObject(\"settings/search/weights_\"+`alpha`+\"_\"+`D`+\"_\"+`stop`, weights)\n",
    "            DumpObject(\"settings/search/gradients_\"+`alpha`+\"_\"+`D`+\"_\"+`stop`, gradients)\n",
    "            DumpObject(\"settings/search/score_liste_\"+`alpha`+\"_\"+`D`+\"_\"+`stop`, scores_liste)\n",
    "            DumpObject(\"settings/search/index_\"+`alpha`+\"_\"+`D`+\"_\"+`stop`, tr)\n",
    "            break\n",
    "        \n",
    "        \n",
    "    return scores_liste, scores_cv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 22s, sys: 6.57 s, total: 5min 28s\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "tar = tarfile.open(\"dac.tar.gz\")\n",
    "%time f = tar.extractfile('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________________ 0.004 | 2097152 _______________________________\n",
      "\n",
      "\n",
      "training ... 1.0 M\n",
      "\t Line : 100000\t logloss: 0.492250\t batch logloss: 0.492250\n",
      "CPU times: user 21.9 s, sys: 641 ms, total: 22.6 s\n",
      "Wall time: 22.9 s\n",
      "\n",
      "training ... 2.0 M\n",
      "\t Line : 200000\t logloss: 0.500252\t batch logloss: 0.508255\n",
      "CPU times: user 23 s, sys: 695 ms, total: 23.6 s\n",
      "Wall time: 25 s\n",
      "\n",
      "training ... 3.0 M\n",
      "\t Line : 300000\t logloss: 0.505277\t batch logloss: 0.515326\n",
      "CPU times: user 22.6 s, sys: 566 ms, total: 23.2 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 4.0 M\n",
      "\t Line : 400000\t logloss: 0.506844\t batch logloss: 0.511545\n",
      "CPU times: user 22.4 s, sys: 446 ms, total: 22.8 s\n",
      "Wall time: 23.1 s\n",
      "\n",
      "training ... 5.0 M\n",
      "\t Line : 500000\t logloss: 0.506967\t batch logloss: 0.507457\n",
      "CPU times: user 22.3 s, sys: 551 ms, total: 22.9 s\n",
      "Wall time: 23.2 s\n",
      "\n",
      "training ... 6.0 M\n",
      "\t Line : 600000\t logloss: 0.505933\t batch logloss: 0.500768\n",
      "CPU times: user 23.1 s, sys: 560 ms, total: 23.6 s\n",
      "Wall time: 24.9 s\n",
      "\n",
      "training ... 7.0 M\n",
      "\t Line : 700000\t logloss: 0.504293\t batch logloss: 0.494450\n",
      "CPU times: user 22.5 s, sys: 487 ms, total: 23 s\n",
      "Wall time: 23.3 s\n",
      "\n",
      "training ... 8.0 M\n",
      "\t Line : 800000\t logloss: 0.502578\t batch logloss: 0.490573\n",
      "CPU times: user 22.4 s, sys: 410 ms, total: 22.8 s\n",
      "Wall time: 23.1 s\n",
      "\n",
      "training ... 9.0 M\n",
      "\t Line : 900000\t logloss: 0.500997\t batch logloss: 0.488348\n",
      "CPU times: user 22 s, sys: 379 ms, total: 22.4 s\n",
      "Wall time: 22.5 s\n",
      "\n",
      "training ... 10.0 M\n",
      "\t Line : 1000000\t logloss: 0.499444\t batch logloss: 0.485467\n",
      "CPU times: user 22.3 s, sys: 489 ms, total: 22.8 s\n",
      "Wall time: 23.1 s\n",
      "\n",
      "training ... 11.0 M\n",
      "\t Line : 1100000\t logloss: 0.498199\t batch logloss: 0.485749\n",
      "CPU times: user 20.4 s, sys: 372 ms, total: 20.8 s\n",
      "Wall time: 21.1 s\n",
      "\n",
      "training ... 12.0 M\n",
      "\t Line : 1200000\t logloss: 0.497202\t batch logloss: 0.486234\n",
      "CPU times: user 22.6 s, sys: 569 ms, total: 23.1 s\n",
      "Wall time: 23.4 s\n",
      "\n",
      "training ... 13.0 M\n",
      "\t Line : 1300000\t logloss: 0.496194\t batch logloss: 0.484098\n",
      "CPU times: user 22.6 s, sys: 422 ms, total: 23 s\n",
      "Wall time: 23.3 s\n",
      "\n",
      "training ... 14.0 M\n",
      "\t Line : 1400000\t logloss: 0.495302\t batch logloss: 0.483708\n",
      "CPU times: user 22.6 s, sys: 630 ms, total: 23.2 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 15.0 M\n",
      "\t Line : 1500000\t logloss: 0.494409\t batch logloss: 0.481910\n",
      "CPU times: user 22.5 s, sys: 437 ms, total: 22.9 s\n",
      "Wall time: 23.2 s\n",
      "\n",
      "training ... 16.0 M\n",
      "\t Line : 1600000\t logloss: 0.493702\t batch logloss: 0.483097\n",
      "CPU times: user 22.2 s, sys: 358 ms, total: 22.6 s\n",
      "Wall time: 22.8 s\n",
      "\n",
      "training ... 17.0 M\n",
      "\t Line : 1700000\t logloss: 0.492911\t batch logloss: 0.480246\n",
      "CPU times: user 21.7 s, sys: 331 ms, total: 22.1 s\n",
      "Wall time: 22.2 s\n",
      "\n",
      "training ... 18.0 M\n",
      "\t Line : 1800000\t logloss: 0.492153\t batch logloss: 0.479272\n",
      "CPU times: user 22.1 s, sys: 376 ms, total: 22.5 s\n",
      "Wall time: 22.6 s\n",
      "\n",
      "training ... 19.0 M\n",
      "\t Line : 1900000\t logloss: 0.491446\t batch logloss: 0.478729\n",
      "CPU times: user 22 s, sys: 368 ms, total: 22.4 s\n",
      "Wall time: 22.5 s\n",
      "\n",
      "training ... 20.0 M\n",
      "\t Line : 2000000\t logloss: 0.490729\t batch logloss: 0.477092\n",
      "CPU times: user 21.2 s, sys: 468 ms, total: 21.7 s\n",
      "Wall time: 22.1 s\n",
      "\n",
      "training ... 21.0 M\n",
      "\t Line : 2100000\t logloss: 0.490086\t batch logloss: 0.477241\n",
      "CPU times: user 20.5 s, sys: 281 ms, total: 20.8 s\n",
      "Wall time: 20.8 s\n",
      "\n",
      "training ... 22.0 M\n",
      "\t Line : 2200000\t logloss: 0.489594\t batch logloss: 0.479247\n",
      "CPU times: user 19.9 s, sys: 244 ms, total: 20.2 s\n",
      "Wall time: 20.2 s\n",
      "\n",
      "training ... 23.0 M\n",
      "\t Line : 2300000\t logloss: 0.489073\t batch logloss: 0.477611\n",
      "CPU times: user 21.2 s, sys: 382 ms, total: 21.6 s\n",
      "Wall time: 21.8 s\n",
      "\n",
      "training ... 24.0 M\n",
      "\t Line : 2400000\t logloss: 0.488573\t batch logloss: 0.477088\n",
      "CPU times: user 20.2 s, sys: 280 ms, total: 20.5 s\n",
      "Wall time: 20.6 s\n",
      "\n",
      "training ... 25.0 M\n",
      "\t Line : 2500000\t logloss: 0.488283\t batch logloss: 0.481315\n",
      "CPU times: user 20.5 s, sys: 320 ms, total: 20.9 s\n",
      "Wall time: 21 s\n",
      "\n",
      "training ... 26.0 M\n",
      "\t Line : 2600000\t logloss: 0.488074\t batch logloss: 0.482857\n",
      "CPU times: user 20.6 s, sys: 333 ms, total: 20.9 s\n",
      "Wall time: 21 s\n",
      "\n",
      "training ... 27.0 M\n",
      "\t Line : 2700000\t logloss: 0.487798\t batch logloss: 0.480615\n",
      "CPU times: user 20.6 s, sys: 331 ms, total: 21 s\n",
      "Wall time: 21.1 s\n",
      "\n",
      "training ... 28.0 M\n",
      "\t Line : 2800000\t logloss: 0.487550\t batch logloss: 0.480859\n",
      "CPU times: user 19.8 s, sys: 252 ms, total: 20.1 s\n",
      "Wall time: 20.1 s\n",
      "\n",
      "training ... 29.0 M\n",
      "\t Line : 2900000\t logloss: 0.487192\t batch logloss: 0.477166\n",
      "CPU times: user 21.4 s, sys: 392 ms, total: 21.8 s\n",
      "Wall time: 22 s\n",
      "\n",
      "training ... 30.0 M\n",
      "\t Line : 3000000\t logloss: 0.486922\t batch logloss: 0.479103\n",
      "CPU times: user 20.7 s, sys: 331 ms, total: 21.1 s\n",
      "Wall time: 21.2 s\n",
      "\n",
      "training ... 31.0 M\n",
      "\t Line : 3100000\t logloss: 0.486781\t batch logloss: 0.482540\n",
      "CPU times: user 21.7 s, sys: 392 ms, total: 22.1 s\n",
      "Wall time: 22.3 s\n",
      "\n",
      "training ... 32.0 M\n",
      "\t Line : 3200000\t logloss: 0.486689\t batch logloss: 0.483836\n",
      "CPU times: user 20.2 s, sys: 287 ms, total: 20.5 s\n",
      "Wall time: 20.6 s\n",
      "\n",
      "training ... 33.0 M\n",
      "\t Line : 3300000\t logloss: 0.486606\t batch logloss: 0.483940\n",
      "CPU times: user 20.7 s, sys: 432 ms, total: 21.1 s\n",
      "Wall time: 21.3 s\n",
      "\n",
      "training ... 34.0 M\n",
      "\t Line : 3400000\t logloss: 0.486337\t batch logloss: 0.477464\n",
      "CPU times: user 20 s, sys: 225 ms, total: 20.2 s\n",
      "Wall time: 20.2 s\n",
      "\n",
      "training ... 35.0 M\n",
      "\t Line : 3500000\t logloss: 0.486121\t batch logloss: 0.478786\n",
      "CPU times: user 19.8 s, sys: 235 ms, total: 20 s\n",
      "Wall time: 20 s\n",
      "\n",
      "training ... 36.0 M\n",
      "\t Line : 3600000\t logloss: 0.485987\t batch logloss: 0.481292\n",
      "CPU times: user 20.1 s, sys: 262 ms, total: 20.4 s\n",
      "Wall time: 20.4 s\n",
      "\n",
      "training ... 37.0 M\n",
      "\t Line : 3700000\t logloss: 0.485834\t batch logloss: 0.480320\n",
      "CPU times: user 19.9 s, sys: 237 ms, total: 20.1 s\n",
      "Wall time: 20.1 s\n",
      "\n",
      "training ... 38.0 M\n",
      "\t Line : 3800000\t logloss: 0.485602\t batch logloss: 0.477020\n",
      "CPU times: user 20 s, sys: 254 ms, total: 20.2 s\n",
      "Wall time: 20.3 s\n",
      "\n",
      "training ... 39.0 M\n",
      "\t Line : 3900000\t logloss: 0.485331\t batch logloss: 0.475033\n",
      "CPU times: user 20.5 s, sys: 311 ms, total: 20.8 s\n",
      "Wall time: 20.9 s\n",
      "\n",
      "training ... 40.0 M\n",
      "\t Line : 4000000\t logloss: 0.484976\t batch logloss: 0.471129\n",
      "CPU times: user 21.5 s, sys: 435 ms, total: 21.9 s\n",
      "Wall time: 22.2 s\n",
      "CPU times: user 15min 29s, sys: 20.6 s, total: 15min 50s\n",
      "Wall time: 16min 2s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABPUAAAKECAYAAABviQ+qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1215972d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "Alphas = [.004]\n",
    "Dim = [21]\n",
    "\n",
    "scores_liste = []\n",
    "scores_cv = []\n",
    "\n",
    "for a in Alphas:\n",
    "    for d in Dim:\n",
    "        %time s_l, s_cv = searchParametres(f, FutureEngineering=[],chunksize = 10**5, separator='\\t', alpha=a, batch_size=10**5, D=2**d, LoadBack=False)\n",
    "        score_loss = []\n",
    "        for i in range(1,len(s_l)):\n",
    "            score_loss.append(s_l[i]/(i*(10**5)))\n",
    "        scores_liste.append(score_loss)\n",
    "        \n",
    "        \n",
    "        scores_cv.append(s_cv[1:])\n",
    "        \n",
    "        #plt.subplot()\n",
    "        #plt.figure(figsize=(12,8))\n",
    "        plt.gcf().set_size_inches(18.5, 10.5)\n",
    "        plt.plot([x for x in xrange(1,len(score_loss)+1)], score_loss, label=\"tr (\"+`a`+\", \"+`d`+\")\")\n",
    "        \"\"\"plt.plot([x for x in xrange(1,len(s_cv))], s_cv[1:], label=\"cv (\"+`a`+\", \"+`d`+\")\")\"\"\"\n",
    "        plt.title('Score Logloss')\n",
    "        plt.xlabel('Training size 10**5')\n",
    "        plt.ylabel('Logloss')\n",
    "        plt.grid(True)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2,borderaxespad=0.)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=2**26 [0.5807208480797399, 0.5678878239212709, 0.5589863048063922]\n",
      "D=2**21 [0.5319759148221538, 0.5241939852361075, 0.5200569971738973] alpha=.009\n",
      "D=2**21 [0.5663985406206096, 0.5544749516387195, 0.5465877890575507] alpha=.005\n",
      "D=2**21 [0.5807007051952747, 0.5678566009810464, 0.5589545041816844] alpha=.004\n",
      "D=2**21 [0.5988616151851411, 0.5856366811329138, 0.5760139182904652] alpha=.003\n",
      "D=2**20 [0.5806881654684463, 0.5678264222803697, 0.5589274861496493]\n",
      "D=2**19 [0.5806802150691512, 0.5677937548628111, 0.5588851363860716]\n",
      "D=2**15 [0.5797051430007961, 0.5666549600990424, 0.5577359617317035]\n",
      "D=2**4  [0.5094971789571355, 0.5133756274015805, 0.5158623845521246]\n"
     ]
    }
   ],
   "source": [
    "score_loss9 = []\n",
    "for i in range(1,len(score_liste)):\n",
    "    score_loss9.append(score_liste[i]/(i*1000))\n",
    "print \"D=2**26\",score_loss1\n",
    "print \"D=2**21\",score_loss9,\"alpha=.009\"\n",
    "print \"D=2**21\",score_loss8,\"alpha=.005\"\n",
    "print \"D=2**21\",score_loss6,\"alpha=.004\"\n",
    "print \"D=2**21\",score_loss7,\"alpha=.003\"\n",
    "print \"D=2**20\",score_loss2\n",
    "print \"D=2**19\",score_loss5\n",
    "print \"D=2**15\",score_loss3\n",
    "print \"D=2**4 \",score_loss4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training ... 1.0 M\n",
      "\t Line : 100000\t logloss: 0.504080\t batch logloss: 0.504080\n",
      "CPU times: user 26.9 s, sys: 1.33 s, total: 28.3 s\n",
      "Wall time: 28.9 s\n",
      "\n",
      "training ... 2.0 M\n",
      "\t Line : 200000\t logloss: 0.511537\t batch logloss: 0.518993\n",
      "CPU times: user 26.6 s, sys: 1.19 s, total: 27.8 s\n",
      "Wall time: 28 s\n",
      "\n",
      "training ... 3.0 M\n",
      "\t Line : 300000\t logloss: 0.515829\t batch logloss: 0.524414\n",
      "CPU times: user 26.2 s, sys: 907 ms, total: 27.1 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 4.0 M\n",
      "\t Line : 400000\t logloss: 0.516884\t batch logloss: 0.520050\n",
      "CPU times: user 26.1 s, sys: 888 ms, total: 27 s\n",
      "Wall time: 27.1 s\n",
      "\n",
      "training ... 5.0 M\n",
      "\t Line : 500000\t logloss: 0.516525\t batch logloss: 0.515088\n",
      "CPU times: user 26.1 s, sys: 940 ms, total: 27 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 6.0 M\n",
      "\t Line : 600000\t logloss: 0.515176\t batch logloss: 0.508431\n",
      "CPU times: user 25.2 s, sys: 964 ms, total: 26.1 s\n",
      "Wall time: 26.2 s\n",
      "\n",
      "training ... 7.0 M\n",
      "\t Line : 700000\t logloss: 0.513258\t batch logloss: 0.501748\n",
      "CPU times: user 25.5 s, sys: 729 ms, total: 26.2 s\n",
      "Wall time: 26.2 s\n",
      "\n",
      "training ... 8.0 M\n",
      "\t Line : 800000\t logloss: 0.511288\t batch logloss: 0.497501\n",
      "CPU times: user 25.1 s, sys: 904 ms, total: 26 s\n",
      "Wall time: 26 s\n",
      "\n",
      "training ... 9.0 M\n",
      "\t Line : 900000\t logloss: 0.509488\t batch logloss: 0.495089\n",
      "CPU times: user 25.2 s, sys: 936 ms, total: 26.2 s\n",
      "Wall time: 26.3 s\n",
      "\n",
      "training ... 10.0 M\n",
      "\t Line : 1000000\t logloss: 0.507771\t batch logloss: 0.492321\n",
      "CPU times: user 26.1 s, sys: 1.05 s, total: 27.1 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 11.0 M\n",
      "\t Line : 1100000\t logloss: 0.506367\t batch logloss: 0.492321\n",
      "CPU times: user 26.9 s, sys: 1.07 s, total: 28 s\n",
      "Wall time: 28.5 s\n",
      "\n",
      "training ... 12.0 M\n",
      "\t Line : 1200000\t logloss: 0.505233\t batch logloss: 0.492766\n",
      "CPU times: user 27 s, sys: 973 ms, total: 27.9 s\n",
      "Wall time: 29.3 s\n",
      "\n",
      "training ... 13.0 M\n",
      "\t Line : 1300000\t logloss: 0.504046\t batch logloss: 0.489792\n",
      "CPU times: user 26.1 s, sys: 1.08 s, total: 27.2 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 14.0 M\n",
      "\t Line : 1400000\t logloss: 0.503026\t batch logloss: 0.489772\n",
      "CPU times: user 26.9 s, sys: 1 s, total: 27.9 s\n",
      "Wall time: 28.6 s\n",
      "\n",
      "training ... 15.0 M\n",
      "\t Line : 1500000\t logloss: 0.501999\t batch logloss: 0.487627\n",
      "CPU times: user 26.6 s, sys: 979 ms, total: 27.5 s\n",
      "Wall time: 27.7 s\n",
      "\n",
      "training ... 16.0 M\n",
      "\t Line : 1600000\t logloss: 0.501154\t batch logloss: 0.488469\n",
      "CPU times: user 26.7 s, sys: 909 ms, total: 27.6 s\n",
      "Wall time: 28 s\n",
      "\n",
      "training ... 17.0 M\n",
      "\t Line : 1700000\t logloss: 0.500260\t batch logloss: 0.485960\n",
      "CPU times: user 27.2 s, sys: 924 ms, total: 28.2 s\n",
      "Wall time: 28.6 s\n",
      "\n",
      "training ... 18.0 M\n",
      "\t Line : 1800000\t logloss: 0.499407\t batch logloss: 0.484910\n",
      "CPU times: user 26.1 s, sys: 986 ms, total: 27.1 s\n",
      "Wall time: 27.2 s\n",
      "\n",
      "training ... 19.0 M\n",
      "\t Line : 1900000\t logloss: 0.498591\t batch logloss: 0.483890\n",
      "CPU times: user 27.5 s, sys: 1.16 s, total: 28.6 s\n",
      "Wall time: 29.1 s\n",
      "\n",
      "training ... 20.0 M\n",
      "\t Line : 2000000\t logloss: 0.497798\t batch logloss: 0.482744\n",
      "CPU times: user 26.1 s, sys: 992 ms, total: 27.1 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 21.0 M\n",
      "\t Line : 2100000\t logloss: 0.497082\t batch logloss: 0.482750\n",
      "CPU times: user 25.1 s, sys: 1.09 s, total: 26.2 s\n",
      "Wall time: 26.3 s\n",
      "\n",
      "training ... 22.0 M\n",
      "\t Line : 2200000\t logloss: 0.496539\t batch logloss: 0.485153\n",
      "CPU times: user 24.3 s, sys: 1.04 s, total: 25.3 s\n",
      "Wall time: 25.1 s\n",
      "\n",
      "training ... 23.0 M\n",
      "\t Line : 2300000\t logloss: 0.495966\t batch logloss: 0.483358\n",
      "CPU times: user 24.3 s, sys: 1.4 s, total: 25.7 s\n",
      "Wall time: 25.1 s\n",
      "\n",
      "training ... 24.0 M\n",
      "\t Line : 2400000\t logloss: 0.495413\t batch logloss: 0.482689\n",
      "CPU times: user 24.1 s, sys: 772 ms, total: 24.8 s\n",
      "Wall time: 24.6 s\n",
      "\n",
      "training ... 25.0 M\n",
      "\t Line : 2500000\t logloss: 0.495076\t batch logloss: 0.486994\n",
      "CPU times: user 24.1 s, sys: 1.07 s, total: 25.2 s\n",
      "Wall time: 24.8 s\n",
      "\n",
      "training ... 26.0 M\n",
      "\t Line : 2600000\t logloss: 0.494816\t batch logloss: 0.488309\n",
      "CPU times: user 24 s, sys: 952 ms, total: 25 s\n",
      "Wall time: 24.8 s\n",
      "\n",
      "training ... 27.0 M\n",
      "\t Line : 2700000\t logloss: 0.494490\t batch logloss: 0.485999\n",
      "CPU times: user 23.9 s, sys: 1.05 s, total: 25 s\n",
      "Wall time: 24.7 s\n",
      "\n",
      "training ... 28.0 M\n",
      "\t Line : 2800000\t logloss: 0.494201\t batch logloss: 0.486398\n",
      "CPU times: user 24 s, sys: 1.07 s, total: 25.1 s\n",
      "Wall time: 24.8 s\n",
      "\n",
      "training ... 29.0 M\n",
      "\t Line : 2900000\t logloss: 0.493804\t batch logloss: 0.482696\n",
      "CPU times: user 24.1 s, sys: 739 ms, total: 24.8 s\n",
      "Wall time: 24.7 s\n",
      "\n",
      "training ... 30.0 M\n",
      "\t Line : 3000000\t logloss: 0.493498\t batch logloss: 0.484622\n",
      "CPU times: user 23.8 s, sys: 751 ms, total: 24.6 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 31.0 M\n",
      "\t Line : 3100000\t logloss: 0.493326\t batch logloss: 0.488159\n",
      "CPU times: user 24.2 s, sys: 1.36 s, total: 25.5 s\n",
      "Wall time: 24.9 s\n",
      "\n",
      "training ... 32.0 M\n",
      "\t Line : 3200000\t logloss: 0.493189\t batch logloss: 0.488958\n",
      "CPU times: user 24.5 s, sys: 1.21 s, total: 25.7 s\n",
      "Wall time: 25.5 s\n",
      "\n",
      "training ... 33.0 M\n",
      "\t Line : 3300000\t logloss: 0.493067\t batch logloss: 0.489173\n",
      "CPU times: user 24.1 s, sys: 1.04 s, total: 25.1 s\n",
      "Wall time: 24.8 s\n",
      "\n",
      "training ... 34.0 M\n",
      "\t Line : 3400000\t logloss: 0.492773\t batch logloss: 0.483058\n",
      "CPU times: user 25.5 s, sys: 1.31 s, total: 26.8 s\n",
      "Wall time: 26.7 s\n",
      "\n",
      "training ... 35.0 M\n",
      "\t Line : 3500000\t logloss: 0.492530\t batch logloss: 0.484260\n",
      "CPU times: user 23.9 s, sys: 809 ms, total: 24.8 s\n",
      "Wall time: 24.5 s\n",
      "\n",
      "training ... 36.0 M\n",
      "\t Line : 3600000\t logloss: 0.492359\t batch logloss: 0.486384\n",
      "CPU times: user 24.2 s, sys: 1.1 s, total: 25.3 s\n",
      "Wall time: 24.9 s\n",
      "\n",
      "training ... 37.0 M\n",
      "\t Line : 3700000\t logloss: 0.492164\t batch logloss: 0.485132\n",
      "CPU times: user 23.9 s, sys: 949 ms, total: 24.8 s\n",
      "Wall time: 24.5 s\n",
      "\n",
      "training ... 38.0 M\n",
      "\t Line : 3800000\t logloss: 0.491898\t batch logloss: 0.482066\n",
      "CPU times: user 24.4 s, sys: 1.25 s, total: 25.6 s\n",
      "Wall time: 25.2 s\n",
      "\n",
      "training ... 39.0 M\n",
      "\t Line : 3900000\t logloss: 0.491587\t batch logloss: 0.479783\n",
      "CPU times: user 24.1 s, sys: 1.15 s, total: 25.2 s\n",
      "Wall time: 24.8 s\n",
      "\n",
      "training ... 40.0 M\n",
      "\t Line : 4000000\t logloss: 0.491212\t batch logloss: 0.476576\n",
      "CPU times: user 24.3 s, sys: 919 ms, total: 25.2 s\n",
      "Wall time: 24.9 s\n",
      "\n",
      "training ... 41.0 M\n",
      "\t Line : 4100000\t logloss: 0.490952\t batch logloss: 0.480567\n",
      "CPU times: user 23.9 s, sys: 303 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 42.0 M\n",
      "\t Line : 4200000\t logloss: 0.490640\t batch logloss: 0.477825\n",
      "CPU times: user 24.4 s, sys: 508 ms, total: 24.9 s\n",
      "Wall time: 24.9 s\n",
      "\n",
      "training ... 43.0 M\n",
      "\t Line : 4300000\t logloss: 0.490422\t batch logloss: 0.481278\n",
      "CPU times: user 23.9 s, sys: 315 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 44.0 M\n",
      "\t Line : 4400000\t logloss: 0.490226\t batch logloss: 0.481789\n",
      "CPU times: user 23.8 s, sys: 301 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 45.0 M\n",
      "\t Line : 4500000\t logloss: 0.489975\t batch logloss: 0.478944\n",
      "CPU times: user 23.7 s, sys: 308 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 46.0 M\n",
      "\t Line : 4600000\t logloss: 0.489880\t batch logloss: 0.485576\n",
      "CPU times: user 23.8 s, sys: 321 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 47.0 M\n",
      "\t Line : 4700000\t logloss: 0.489672\t batch logloss: 0.480120\n",
      "CPU times: user 24.2 s, sys: 398 ms, total: 24.6 s\n",
      "Wall time: 24.6 s\n",
      "\n",
      "training ... 48.0 M\n",
      "\t Line : 4800000\t logloss: 0.489451\t batch logloss: 0.479073\n",
      "CPU times: user 24 s, sys: 306 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 49.0 M\n",
      "\t Line : 4900000\t logloss: 0.489330\t batch logloss: 0.483527\n",
      "CPU times: user 23.9 s, sys: 298 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 50.0 M\n",
      "\t Line : 5000000\t logloss: 0.489195\t batch logloss: 0.482564\n",
      "CPU times: user 23.9 s, sys: 297 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 51.0 M\n",
      "\t Line : 5100000\t logloss: 0.489032\t batch logloss: 0.480877\n",
      "CPU times: user 23.9 s, sys: 288 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 52.0 M\n",
      "\t Line : 5200000\t logloss: 0.488790\t batch logloss: 0.476464\n",
      "CPU times: user 24 s, sys: 290 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 53.0 M\n",
      "\t Line : 5300000\t logloss: 0.488629\t batch logloss: 0.480258\n",
      "CPU times: user 24 s, sys: 305 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 54.0 M\n",
      "\t Line : 5400000\t logloss: 0.488460\t batch logloss: 0.479519\n",
      "CPU times: user 23.8 s, sys: 302 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 55.0 M\n",
      "\t Line : 5500000\t logloss: 0.488385\t batch logloss: 0.484320\n",
      "CPU times: user 23.8 s, sys: 299 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 56.0 M\n",
      "\t Line : 5600000\t logloss: 0.488213\t batch logloss: 0.478725\n",
      "CPU times: user 23.9 s, sys: 287 ms, total: 24.1 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 57.0 M\n",
      "\t Line : 5700000\t logloss: 0.488053\t batch logloss: 0.479117\n",
      "CPU times: user 23.8 s, sys: 293 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 58.0 M\n",
      "\t Line : 5800000\t logloss: 0.487902\t batch logloss: 0.479314\n",
      "CPU times: user 23.8 s, sys: 303 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 59.0 M\n",
      "\t Line : 5900000\t logloss: 0.487727\t batch logloss: 0.477571\n",
      "CPU times: user 24.1 s, sys: 382 ms, total: 24.5 s\n",
      "Wall time: 24.5 s\n",
      "\n",
      "training ... 60.0 M\n",
      "\t Line : 6000000\t logloss: 0.487607\t batch logloss: 0.480525\n",
      "CPU times: user 24.4 s, sys: 341 ms, total: 24.7 s\n",
      "Wall time: 24.8 s\n",
      "\n",
      "training ... 61.0 M\n",
      "\t Line : 6100000\t logloss: 0.487386\t batch logloss: 0.474114\n",
      "CPU times: user 23.9 s, sys: 309 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 62.0 M\n",
      "\t Line : 6200000\t logloss: 0.487169\t batch logloss: 0.473945\n",
      "CPU times: user 24 s, sys: 299 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 63.0 M\n",
      "\t Line : 6300000\t logloss: 0.486887\t batch logloss: 0.469363\n",
      "CPU times: user 23.9 s, sys: 297 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 64.0 M\n",
      "\t Line : 6400000\t logloss: 0.486556\t batch logloss: 0.465733\n",
      "CPU times: user 24.1 s, sys: 306 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 65.0 M\n",
      "\t Line : 6500000\t logloss: 0.486068\t batch logloss: 0.454808\n",
      "CPU times: user 24.1 s, sys: 309 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 66.0 M\n",
      "\t Line : 6600000\t logloss: 0.485818\t batch logloss: 0.469608\n",
      "CPU times: user 23.9 s, sys: 316 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 67.0 M\n",
      "\t Line : 6700000\t logloss: 0.486153\t batch logloss: 0.508248\n",
      "CPU times: user 24.2 s, sys: 349 ms, total: 24.5 s\n",
      "Wall time: 24.6 s\n",
      "\n",
      "training ... 68.0 M\n",
      "\t Line : 6800000\t logloss: 0.486458\t batch logloss: 0.506913\n",
      "CPU times: user 27 s, sys: 774 ms, total: 27.7 s\n",
      "Wall time: 28.1 s\n",
      "\n",
      "training ... 69.0 M\n",
      "\t Line : 6900000\t logloss: 0.486742\t batch logloss: 0.506031\n",
      "CPU times: user 26.8 s, sys: 518 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 70.0 M\n",
      "\t Line : 7000000\t logloss: 0.486870\t batch logloss: 0.495692\n",
      "CPU times: user 27.2 s, sys: 520 ms, total: 27.7 s\n",
      "Wall time: 27.8 s\n",
      "\n",
      "training ... 71.0 M\n",
      "\t Line : 7100000\t logloss: 0.486992\t batch logloss: 0.495541\n",
      "CPU times: user 26.8 s, sys: 496 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 72.0 M\n",
      "\t Line : 7200000\t logloss: 0.487023\t batch logloss: 0.489206\n",
      "CPU times: user 27 s, sys: 796 ms, total: 27.8 s\n",
      "Wall time: 28 s\n",
      "\n",
      "training ... 73.0 M\n",
      "\t Line : 7300000\t logloss: 0.487007\t batch logloss: 0.485905\n",
      "CPU times: user 27.1 s, sys: 497 ms, total: 27.6 s\n",
      "Wall time: 27.7 s\n",
      "\n",
      "training ... 74.0 M\n",
      "\t Line : 7400000\t logloss: 0.486962\t batch logloss: 0.483680\n",
      "CPU times: user 27.2 s, sys: 512 ms, total: 27.7 s\n",
      "Wall time: 27.8 s\n",
      "\n",
      "training ... 75.0 M\n",
      "\t Line : 7500000\t logloss: 0.486903\t batch logloss: 0.482483\n",
      "CPU times: user 27.1 s, sys: 513 ms, total: 27.6 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 76.0 M\n",
      "\t Line : 7600000\t logloss: 0.486844\t batch logloss: 0.482473\n",
      "CPU times: user 27.1 s, sys: 511 ms, total: 27.6 s\n",
      "Wall time: 27.7 s\n",
      "\n",
      "training ... 77.0 M\n",
      "\t Line : 7700000\t logloss: 0.486808\t batch logloss: 0.484022\n",
      "CPU times: user 27.1 s, sys: 540 ms, total: 27.7 s\n",
      "Wall time: 27.7 s\n",
      "\n",
      "training ... 78.0 M\n",
      "\t Line : 7800000\t logloss: 0.486715\t batch logloss: 0.479567\n",
      "CPU times: user 26.8 s, sys: 562 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 79.0 M\n",
      "\t Line : 7900000\t logloss: 0.486545\t batch logloss: 0.473321\n",
      "CPU times: user 27.1 s, sys: 682 ms, total: 27.8 s\n",
      "Wall time: 27.9 s\n",
      "\n",
      "training ... 80.0 M\n",
      "\t Line : 8000000\t logloss: 0.486367\t batch logloss: 0.472277\n",
      "CPU times: user 27 s, sys: 521 ms, total: 27.5 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 81.0 M\n",
      "\t Line : 8100000\t logloss: 0.486175\t batch logloss: 0.470833\n",
      "CPU times: user 26.8 s, sys: 523 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 82.0 M\n",
      "\t Line : 8200000\t logloss: 0.486005\t batch logloss: 0.472207\n",
      "CPU times: user 27.6 s, sys: 540 ms, total: 28.1 s\n",
      "Wall time: 28.2 s\n",
      "\n",
      "training ... 83.0 M\n",
      "\t Line : 8300000\t logloss: 0.485875\t batch logloss: 0.475214\n",
      "CPU times: user 27.2 s, sys: 613 ms, total: 27.8 s\n",
      "Wall time: 27.9 s\n",
      "\n",
      "training ... 84.0 M\n",
      "\t Line : 8400000\t logloss: 0.485776\t batch logloss: 0.477584\n",
      "CPU times: user 27.2 s, sys: 507 ms, total: 27.7 s\n",
      "Wall time: 27.8 s\n",
      "\n",
      "training ... 85.0 M\n",
      "\t Line : 8500000\t logloss: 0.485679\t batch logloss: 0.477472\n",
      "CPU times: user 26.6 s, sys: 499 ms, total: 27.1 s\n",
      "Wall time: 27.2 s\n",
      "\n",
      "training ... 86.0 M\n",
      "\t Line : 8600000\t logloss: 0.485652\t batch logloss: 0.483362\n",
      "CPU times: user 26.8 s, sys: 510 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 87.0 M\n",
      "\t Line : 8700000\t logloss: 0.485589\t batch logloss: 0.480243\n",
      "CPU times: user 26.8 s, sys: 508 ms, total: 27.3 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 88.0 M\n",
      "\t Line : 8800000\t logloss: 0.485551\t batch logloss: 0.482207\n",
      "CPU times: user 26.4 s, sys: 475 ms, total: 26.9 s\n",
      "Wall time: 27 s\n",
      "\n",
      "training ... 89.0 M\n",
      "\t Line : 8900000\t logloss: 0.485545\t batch logloss: 0.485031\n",
      "CPU times: user 26.8 s, sys: 531 ms, total: 27.4 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 90.0 M\n",
      "\t Line : 9000000\t logloss: 0.485520\t batch logloss: 0.483249\n",
      "CPU times: user 26.9 s, sys: 515 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 91.0 M\n",
      "\t Line : 9100000\t logloss: 0.485482\t batch logloss: 0.482050\n",
      "CPU times: user 27 s, sys: 499 ms, total: 27.5 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 92.0 M\n",
      "\t Line : 9200000\t logloss: 0.485476\t batch logloss: 0.484957\n",
      "CPU times: user 26.8 s, sys: 490 ms, total: 27.3 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 93.0 M\n",
      "\t Line : 9300000\t logloss: 0.485475\t batch logloss: 0.485405\n",
      "CPU times: user 27 s, sys: 491 ms, total: 27.5 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 94.0 M\n",
      "\t Line : 9400000\t logloss: 0.485500\t batch logloss: 0.487850\n",
      "CPU times: user 27 s, sys: 564 ms, total: 27.6 s\n",
      "Wall time: 27.7 s\n",
      "\n",
      "training ... 95.0 M\n",
      "\t Line : 9500000\t logloss: 0.485583\t batch logloss: 0.493337\n",
      "CPU times: user 26.7 s, sys: 483 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 96.0 M\n",
      "\t Line : 9600000\t logloss: 0.485702\t batch logloss: 0.496985\n",
      "CPU times: user 26.9 s, sys: 491 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 97.0 M\n",
      "\t Line : 9700000\t logloss: 0.485747\t batch logloss: 0.490100\n",
      "CPU times: user 26.6 s, sys: 478 ms, total: 27.1 s\n",
      "Wall time: 27.2 s\n",
      "\n",
      "training ... 98.0 M\n",
      "\t Line : 9800000\t logloss: 0.485773\t batch logloss: 0.488335\n",
      "CPU times: user 26.8 s, sys: 478 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 99.0 M\n",
      "\t Line : 9900000\t logloss: 0.485815\t batch logloss: 0.489877\n",
      "CPU times: user 26.6 s, sys: 494 ms, total: 27.1 s\n",
      "Wall time: 27.2 s\n",
      "\n",
      "training ... 100.0 M\n",
      "\t Line : 10000000\t logloss: 0.485870\t batch logloss: 0.491326\n",
      "CPU times: user 26.7 s, sys: 480 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 101.0 M\n",
      "\t Line : 10100000\t logloss: 0.485896\t batch logloss: 0.488508\n",
      "CPU times: user 26.6 s, sys: 489 ms, total: 27 s\n",
      "Wall time: 27.1 s\n",
      "\n",
      "training ... 102.0 M\n",
      "\t Line : 10200000\t logloss: 0.485910\t batch logloss: 0.487338\n",
      "CPU times: user 26.7 s, sys: 502 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 103.0 M\n",
      "\t Line : 10300000\t logloss: 0.485928\t batch logloss: 0.487781\n",
      "CPU times: user 26.8 s, sys: 511 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 104.0 M\n",
      "\t Line : 10400000\t logloss: 0.485934\t batch logloss: 0.486561\n",
      "CPU times: user 26.6 s, sys: 486 ms, total: 27.1 s\n",
      "Wall time: 27.2 s\n",
      "\n",
      "training ... 105.0 M\n",
      "\t Line : 10500000\t logloss: 0.485896\t batch logloss: 0.481887\n",
      "CPU times: user 26.9 s, sys: 519 ms, total: 27.4 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 106.0 M\n",
      "\t Line : 10600000\t logloss: 0.485891\t batch logloss: 0.485410\n",
      "CPU times: user 27 s, sys: 696 ms, total: 27.7 s\n",
      "Wall time: 27.8 s\n",
      "\n",
      "training ... 107.0 M\n",
      "\t Line : 10700000\t logloss: 0.485876\t batch logloss: 0.484301\n",
      "CPU times: user 26.3 s, sys: 481 ms, total: 26.8 s\n",
      "Wall time: 26.9 s\n",
      "\n",
      "training ... 108.0 M\n",
      "\t Line : 10800000\t logloss: 0.485875\t batch logloss: 0.485767\n",
      "CPU times: user 26.7 s, sys: 502 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 109.0 M\n",
      "\t Line : 10900000\t logloss: 0.485864\t batch logloss: 0.484626\n",
      "CPU times: user 26.8 s, sys: 501 ms, total: 27.3 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 110.0 M\n",
      "\t Line : 11000000\t logloss: 0.485863\t batch logloss: 0.485718\n",
      "CPU times: user 26.7 s, sys: 514 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 111.0 M\n",
      "\t Line : 11100000\t logloss: 0.485873\t batch logloss: 0.487021\n",
      "CPU times: user 26.7 s, sys: 493 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 112.0 M\n",
      "\t Line : 11200000\t logloss: 0.485870\t batch logloss: 0.485493\n",
      "CPU times: user 26.7 s, sys: 511 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 113.0 M\n",
      "\t Line : 11300000\t logloss: 0.485869\t batch logloss: 0.485780\n",
      "CPU times: user 26.9 s, sys: 526 ms, total: 27.5 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 114.0 M\n",
      "\t Line : 11400000\t logloss: 0.485864\t batch logloss: 0.485262\n",
      "CPU times: user 26.7 s, sys: 504 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 115.0 M\n",
      "\t Line : 11500000\t logloss: 0.485844\t batch logloss: 0.483558\n",
      "CPU times: user 26.9 s, sys: 502 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 116.0 M\n",
      "\t Line : 11600000\t logloss: 0.485782\t batch logloss: 0.478717\n",
      "CPU times: user 26.7 s, sys: 495 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 117.0 M\n",
      "\t Line : 11700000\t logloss: 0.485742\t batch logloss: 0.481097\n",
      "CPU times: user 26.9 s, sys: 575 ms, total: 27.5 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 118.0 M\n",
      "\t Line : 11800000\t logloss: 0.485721\t batch logloss: 0.483254\n",
      "CPU times: user 26.5 s, sys: 501 ms, total: 27 s\n",
      "Wall time: 27.1 s\n",
      "\n",
      "training ... 119.0 M\n",
      "\t Line : 11900000\t logloss: 0.485651\t batch logloss: 0.477399\n",
      "CPU times: user 26.9 s, sys: 501 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 120.0 M\n",
      "\t Line : 12000000\t logloss: 0.485601\t batch logloss: 0.479653\n",
      "CPU times: user 26.9 s, sys: 523 ms, total: 27.5 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 121.0 M\n",
      "\t Line : 12100000\t logloss: 0.485534\t batch logloss: 0.477493\n",
      "CPU times: user 26.9 s, sys: 499 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 122.0 M\n",
      "\t Line : 12200000\t logloss: 0.485486\t batch logloss: 0.479644\n",
      "CPU times: user 26.9 s, sys: 497 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 123.0 M\n",
      "\t Line : 12300000\t logloss: 0.485391\t batch logloss: 0.473813\n",
      "CPU times: user 27.2 s, sys: 488 ms, total: 27.6 s\n",
      "Wall time: 27.7 s\n",
      "\n",
      "training ... 124.0 M\n",
      "\t Line : 12400000\t logloss: 0.485264\t batch logloss: 0.469705\n",
      "CPU times: user 27.1 s, sys: 500 ms, total: 27.6 s\n",
      "Wall time: 27.7 s\n",
      "\n",
      "training ... 125.0 M\n",
      "\t Line : 12500000\t logloss: 0.485061\t batch logloss: 0.459860\n",
      "CPU times: user 26.9 s, sys: 484 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 126.0 M\n",
      "\t Line : 12600000\t logloss: 0.484819\t batch logloss: 0.454585\n",
      "CPU times: user 26.8 s, sys: 505 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 127.0 M\n",
      "\t Line : 12700000\t logloss: 0.484685\t batch logloss: 0.467752\n",
      "CPU times: user 26.8 s, sys: 501 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 128.0 M\n",
      "\t Line : 12800000\t logloss: 0.484896\t batch logloss: 0.511750\n",
      "CPU times: user 27.3 s, sys: 538 ms, total: 27.8 s\n",
      "Wall time: 27.9 s\n",
      "\n",
      "training ... 129.0 M\n",
      "\t Line : 12900000\t logloss: 0.485124\t batch logloss: 0.514233\n",
      "CPU times: user 26.5 s, sys: 496 ms, total: 27 s\n",
      "Wall time: 27.1 s\n",
      "\n",
      "training ... 130.0 M\n",
      "\t Line : 13000000\t logloss: 0.485284\t batch logloss: 0.505969\n",
      "CPU times: user 26.6 s, sys: 490 ms, total: 27.1 s\n",
      "Wall time: 27.2 s\n",
      "\n",
      "training ... 131.0 M\n",
      "\t Line : 13100000\t logloss: 0.485428\t batch logloss: 0.504183\n",
      "CPU times: user 26.9 s, sys: 527 ms, total: 27.5 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 132.0 M\n",
      "\t Line : 13200000\t logloss: 0.485540\t batch logloss: 0.500126\n",
      "CPU times: user 26.8 s, sys: 497 ms, total: 27.3 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 133.0 M\n",
      "\t Line : 13300000\t logloss: 0.485622\t batch logloss: 0.496529\n",
      "CPU times: user 26.8 s, sys: 499 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 134.0 M\n",
      "\t Line : 13400000\t logloss: 0.485657\t batch logloss: 0.490297\n",
      "CPU times: user 26.7 s, sys: 511 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 135.0 M\n",
      "\t Line : 13500000\t logloss: 0.485692\t batch logloss: 0.490345\n",
      "CPU times: user 26.8 s, sys: 493 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 136.0 M\n",
      "\t Line : 13600000\t logloss: 0.485702\t batch logloss: 0.487131\n",
      "CPU times: user 27 s, sys: 523 ms, total: 27.6 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 137.0 M\n",
      "\t Line : 13700000\t logloss: 0.485708\t batch logloss: 0.486489\n",
      "CPU times: user 27 s, sys: 495 ms, total: 27.5 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 138.0 M\n",
      "\t Line : 13800000\t logloss: 0.485712\t batch logloss: 0.486232\n",
      "CPU times: user 27.1 s, sys: 535 ms, total: 27.7 s\n",
      "Wall time: 27.8 s\n",
      "\n",
      "training ... 139.0 M\n",
      "\t Line : 13900000\t logloss: 0.485686\t batch logloss: 0.482041\n",
      "CPU times: user 27 s, sys: 513 ms, total: 27.5 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 140.0 M\n",
      "\t Line : 14000000\t logloss: 0.485642\t batch logloss: 0.479541\n",
      "CPU times: user 27.4 s, sys: 534 ms, total: 27.9 s\n",
      "Wall time: 28 s\n",
      "\n",
      "training ... 141.0 M\n",
      "\t Line : 14100000\t logloss: 0.485615\t batch logloss: 0.481833\n",
      "CPU times: user 26.8 s, sys: 489 ms, total: 27.3 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 142.0 M\n",
      "\t Line : 14200000\t logloss: 0.485570\t batch logloss: 0.479335\n",
      "CPU times: user 26.7 s, sys: 501 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n",
      "\n",
      "training ... 143.0 M\n",
      "\t Line : 14300000\t logloss: 0.485541\t batch logloss: 0.481343\n",
      "CPU times: user 27 s, sys: 484 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 144.0 M\n",
      "\t Line : 14400000\t logloss: 0.485487\t batch logloss: 0.477757\n",
      "CPU times: user 27.6 s, sys: 526 ms, total: 28.1 s\n",
      "Wall time: 28.2 s\n",
      "\n",
      "training ... 145.0 M\n",
      "\t Line : 14500000\t logloss: 0.485416\t batch logloss: 0.475264\n",
      "CPU times: user 26.9 s, sys: 528 ms, total: 27.4 s\n",
      "Wall time: 27.5 s\n",
      "\n",
      "training ... 146.0 M\n",
      "\t Line : 14600000\t logloss: 0.485367\t batch logloss: 0.478262\n",
      "CPU times: user 27 s, sys: 484 ms, total: 27.5 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 147.0 M\n",
      "\t Line : 14700000\t logloss: 0.485315\t batch logloss: 0.477669\n",
      "CPU times: user 26.5 s, sys: 500 ms, total: 27 s\n",
      "Wall time: 27.1 s\n",
      "\n",
      "training ... 148.0 M\n",
      "\t Line : 14800000\t logloss: 0.485275\t batch logloss: 0.479323\n",
      "CPU times: user 27.1 s, sys: 478 ms, total: 27.5 s\n",
      "Wall time: 27.6 s\n",
      "\n",
      "training ... 149.0 M\n",
      "\t Line : 14900000\t logloss: 0.485226\t batch logloss: 0.478102\n",
      "CPU times: user 27.2 s, sys: 506 ms, total: 27.7 s\n",
      "Wall time: 27.8 s\n",
      "\n",
      "training ... 150.0 M\n",
      "\t Line : 15000000\t logloss: 0.485195\t batch logloss: 0.480487\n",
      "CPU times: user 26.7 s, sys: 500 ms, total: 27.2 s\n",
      "Wall time: 27.4 s\n",
      "\n",
      "training ... 151.0 M\n",
      "\t Line : 15100000\t logloss: 0.485162\t batch logloss: 0.480247\n",
      "CPU times: user 24.4 s, sys: 324 ms, total: 24.7 s\n",
      "Wall time: 24.8 s\n",
      "\n",
      "training ... 152.0 M\n",
      "\t Line : 15200000\t logloss: 0.485109\t batch logloss: 0.477170\n",
      "CPU times: user 23.8 s, sys: 282 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 153.0 M\n",
      "\t Line : 15300000\t logloss: 0.485069\t batch logloss: 0.479000\n",
      "CPU times: user 24 s, sys: 277 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 154.0 M\n",
      "\t Line : 15400000\t logloss: 0.485038\t batch logloss: 0.480225\n",
      "CPU times: user 23.7 s, sys: 274 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 155.0 M\n",
      "\t Line : 15500000\t logloss: 0.485018\t batch logloss: 0.481883\n",
      "CPU times: user 23.8 s, sys: 272 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 156.0 M\n",
      "\t Line : 15600000\t logloss: 0.484988\t batch logloss: 0.480424\n",
      "CPU times: user 23.7 s, sys: 280 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 157.0 M\n",
      "\t Line : 15700000\t logloss: 0.484972\t batch logloss: 0.482396\n",
      "CPU times: user 23.8 s, sys: 295 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 158.0 M\n",
      "\t Line : 15800000\t logloss: 0.484963\t batch logloss: 0.483585\n",
      "CPU times: user 23.8 s, sys: 284 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 159.0 M\n",
      "\t Line : 15900000\t logloss: 0.484941\t batch logloss: 0.481453\n",
      "CPU times: user 24.2 s, sys: 389 ms, total: 24.6 s\n",
      "Wall time: 24.6 s\n",
      "\n",
      "training ... 160.0 M\n",
      "\t Line : 16000000\t logloss: 0.484939\t batch logloss: 0.484689\n",
      "CPU times: user 23.9 s, sys: 281 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 161.0 M\n",
      "\t Line : 16100000\t logloss: 0.484919\t batch logloss: 0.481701\n",
      "CPU times: user 23.7 s, sys: 284 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 162.0 M\n",
      "\t Line : 16200000\t logloss: 0.484932\t batch logloss: 0.486958\n",
      "CPU times: user 23.8 s, sys: 278 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 163.0 M\n",
      "\t Line : 16300000\t logloss: 0.484922\t batch logloss: 0.483376\n",
      "CPU times: user 23.7 s, sys: 262 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 164.0 M\n",
      "\t Line : 16400000\t logloss: 0.484905\t batch logloss: 0.482080\n",
      "CPU times: user 23.9 s, sys: 308 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 165.0 M\n",
      "\t Line : 16500000\t logloss: 0.484883\t batch logloss: 0.481329\n",
      "CPU times: user 23.8 s, sys: 289 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 166.0 M\n",
      "\t Line : 16600000\t logloss: 0.484855\t batch logloss: 0.480151\n",
      "CPU times: user 23.9 s, sys: 272 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 167.0 M\n",
      "\t Line : 16700000\t logloss: 0.484836\t batch logloss: 0.481679\n",
      "CPU times: user 23.8 s, sys: 280 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 168.0 M\n",
      "\t Line : 16800000\t logloss: 0.484796\t batch logloss: 0.478096\n",
      "CPU times: user 23.9 s, sys: 267 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 169.0 M\n",
      "\t Line : 16900000\t logloss: 0.484734\t batch logloss: 0.474422\n",
      "CPU times: user 23.7 s, sys: 267 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 170.0 M\n",
      "\t Line : 17000000\t logloss: 0.484684\t batch logloss: 0.476234\n",
      "CPU times: user 23.9 s, sys: 279 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 171.0 M\n",
      "\t Line : 17100000\t logloss: 0.484633\t batch logloss: 0.475970\n",
      "CPU times: user 23.8 s, sys: 263 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 172.0 M\n",
      "\t Line : 17200000\t logloss: 0.484614\t batch logloss: 0.481347\n",
      "CPU times: user 23.8 s, sys: 283 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 173.0 M\n",
      "\t Line : 17300000\t logloss: 0.484603\t batch logloss: 0.482752\n",
      "CPU times: user 23.9 s, sys: 279 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 174.0 M\n",
      "\t Line : 17400000\t logloss: 0.484558\t batch logloss: 0.476640\n",
      "CPU times: user 23.7 s, sys: 270 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 175.0 M\n",
      "\t Line : 17500000\t logloss: 0.484520\t batch logloss: 0.477931\n",
      "CPU times: user 23.9 s, sys: 280 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 176.0 M\n",
      "\t Line : 17600000\t logloss: 0.484503\t batch logloss: 0.481605\n",
      "CPU times: user 23.8 s, sys: 264 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 177.0 M\n",
      "\t Line : 17700000\t logloss: 0.484472\t batch logloss: 0.478986\n",
      "CPU times: user 23.9 s, sys: 307 ms, total: 24.2 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 178.0 M\n",
      "\t Line : 17800000\t logloss: 0.484442\t batch logloss: 0.479205\n",
      "CPU times: user 23.6 s, sys: 265 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 179.0 M\n",
      "\t Line : 17900000\t logloss: 0.484406\t batch logloss: 0.477878\n",
      "CPU times: user 23.7 s, sys: 261 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 180.0 M\n",
      "\t Line : 18000000\t logloss: 0.484390\t batch logloss: 0.481581\n",
      "CPU times: user 24 s, sys: 283 ms, total: 24.3 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 181.0 M\n",
      "\t Line : 18100000\t logloss: 0.484347\t batch logloss: 0.476591\n",
      "CPU times: user 23.9 s, sys: 287 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 182.0 M\n",
      "\t Line : 18200000\t logloss: 0.484287\t batch logloss: 0.473423\n",
      "CPU times: user 23.7 s, sys: 282 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 183.0 M\n",
      "\t Line : 18300000\t logloss: 0.484221\t batch logloss: 0.472138\n",
      "CPU times: user 23.7 s, sys: 269 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 184.0 M\n",
      "\t Line : 18400000\t logloss: 0.484162\t batch logloss: 0.473534\n",
      "CPU times: user 23.7 s, sys: 270 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 185.0 M\n",
      "\t Line : 18500000\t logloss: 0.484140\t batch logloss: 0.480090\n",
      "CPU times: user 23.8 s, sys: 267 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 186.0 M\n",
      "\t Line : 18600000\t logloss: 0.484099\t batch logloss: 0.476444\n",
      "CPU times: user 23.9 s, sys: 284 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 187.0 M\n",
      "\t Line : 18700000\t logloss: 0.484058\t batch logloss: 0.476445\n",
      "CPU times: user 23.8 s, sys: 280 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 188.0 M\n",
      "\t Line : 18800000\t logloss: 0.484026\t batch logloss: 0.478026\n",
      "CPU times: user 23.8 s, sys: 287 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 189.0 M\n",
      "\t Line : 18900000\t logloss: 0.483995\t batch logloss: 0.478149\n",
      "CPU times: user 23.8 s, sys: 277 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 190.0 M\n",
      "\t Line : 19000000\t logloss: 0.483957\t batch logloss: 0.476755\n",
      "CPU times: user 24 s, sys: 311 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 191.0 M\n",
      "\t Line : 19100000\t logloss: 0.483929\t batch logloss: 0.478688\n",
      "CPU times: user 23.7 s, sys: 278 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 192.0 M\n",
      "\t Line : 19200000\t logloss: 0.483898\t batch logloss: 0.477895\n",
      "CPU times: user 23.8 s, sys: 264 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 193.0 M\n",
      "\t Line : 19300000\t logloss: 0.483833\t batch logloss: 0.471395\n",
      "CPU times: user 23.9 s, sys: 277 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 194.0 M\n",
      "\t Line : 19400000\t logloss: 0.483709\t batch logloss: 0.459825\n",
      "CPU times: user 23.9 s, sys: 282 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 195.0 M\n",
      "\t Line : 19500000\t logloss: 0.483675\t batch logloss: 0.476954\n",
      "CPU times: user 23.6 s, sys: 262 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 196.0 M\n",
      "\t Line : 19600000\t logloss: 0.483697\t batch logloss: 0.488090\n",
      "CPU times: user 23.8 s, sys: 271 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 197.0 M\n",
      "\t Line : 19700000\t logloss: 0.483747\t batch logloss: 0.493498\n",
      "CPU times: user 23.9 s, sys: 284 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 198.0 M\n",
      "\t Line : 19800000\t logloss: 0.483781\t batch logloss: 0.490572\n",
      "CPU times: user 23.9 s, sys: 267 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 199.0 M\n",
      "\t Line : 19900000\t logloss: 0.483799\t batch logloss: 0.487287\n",
      "CPU times: user 23.7 s, sys: 277 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 200.0 M\n",
      "\t Line : 20000000\t logloss: 0.483805\t batch logloss: 0.484997\n",
      "CPU times: user 24 s, sys: 268 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 201.0 M\n",
      "\t Line : 20100000\t logloss: 0.483785\t batch logloss: 0.479702\n",
      "CPU times: user 23.8 s, sys: 274 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 202.0 M\n",
      "\t Line : 20200000\t logloss: 0.483768\t batch logloss: 0.480399\n",
      "CPU times: user 23.7 s, sys: 271 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 203.0 M\n",
      "\t Line : 20300000\t logloss: 0.483747\t batch logloss: 0.479509\n",
      "CPU times: user 23.9 s, sys: 383 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 204.0 M\n",
      "\t Line : 20400000\t logloss: 0.483710\t batch logloss: 0.476200\n",
      "CPU times: user 23.9 s, sys: 280 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 205.0 M\n",
      "\t Line : 20500000\t logloss: 0.483672\t batch logloss: 0.475859\n",
      "CPU times: user 23.9 s, sys: 265 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 206.0 M\n",
      "\t Line : 20600000\t logloss: 0.483659\t batch logloss: 0.481046\n",
      "CPU times: user 23.8 s, sys: 277 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 207.0 M\n",
      "\t Line : 20700000\t logloss: 0.483633\t batch logloss: 0.478331\n",
      "CPU times: user 23.6 s, sys: 272 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 208.0 M\n",
      "\t Line : 20800000\t logloss: 0.483601\t batch logloss: 0.476876\n",
      "CPU times: user 23.7 s, sys: 267 ms, total: 24 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 209.0 M\n",
      "\t Line : 20900000\t logloss: 0.483572\t batch logloss: 0.477670\n",
      "CPU times: user 24.2 s, sys: 275 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 210.0 M\n",
      "\t Line : 21000000\t logloss: 0.483528\t batch logloss: 0.474312\n",
      "CPU times: user 23.8 s, sys: 279 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 211.0 M\n",
      "\t Line : 21100000\t logloss: 0.483464\t batch logloss: 0.469893\n",
      "CPU times: user 23.7 s, sys: 260 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 212.0 M\n",
      "\t Line : 21200000\t logloss: 0.483363\t batch logloss: 0.462162\n",
      "CPU times: user 23.9 s, sys: 269 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 213.0 M\n",
      "\t Line : 21300000\t logloss: 0.483264\t batch logloss: 0.462203\n",
      "CPU times: user 23.8 s, sys: 281 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 214.0 M\n",
      "\t Line : 21400000\t logloss: 0.483166\t batch logloss: 0.462393\n",
      "CPU times: user 24.3 s, sys: 289 ms, total: 24.6 s\n",
      "Wall time: 24.6 s\n",
      "\n",
      "training ... 215.0 M\n",
      "\t Line : 21500000\t logloss: 0.483081\t batch logloss: 0.464812\n",
      "CPU times: user 24 s, sys: 274 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 216.0 M\n",
      "\t Line : 21600000\t logloss: 0.483017\t batch logloss: 0.469233\n",
      "CPU times: user 23.9 s, sys: 363 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 217.0 M\n",
      "\t Line : 21700000\t logloss: 0.482947\t batch logloss: 0.467937\n",
      "CPU times: user 23.9 s, sys: 276 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 218.0 M\n",
      "\t Line : 21800000\t logloss: 0.482864\t batch logloss: 0.464803\n",
      "CPU times: user 23.7 s, sys: 268 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 219.0 M\n",
      "\t Line : 21900000\t logloss: 0.482809\t batch logloss: 0.470871\n",
      "CPU times: user 24 s, sys: 256 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 220.0 M\n",
      "\t Line : 22000000\t logloss: 0.482763\t batch logloss: 0.472635\n",
      "CPU times: user 23.9 s, sys: 266 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 221.0 M\n",
      "\t Line : 22100000\t logloss: 0.482724\t batch logloss: 0.474182\n",
      "CPU times: user 23.8 s, sys: 286 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 222.0 M\n",
      "\t Line : 22200000\t logloss: 0.482681\t batch logloss: 0.473075\n",
      "CPU times: user 23.7 s, sys: 282 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 223.0 M\n",
      "\t Line : 22300000\t logloss: 0.482650\t batch logloss: 0.475913\n",
      "CPU times: user 24.1 s, sys: 290 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 224.0 M\n",
      "\t Line : 22400000\t logloss: 0.482668\t batch logloss: 0.486667\n",
      "CPU times: user 23.8 s, sys: 274 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 225.0 M\n",
      "\t Line : 22500000\t logloss: 0.482657\t batch logloss: 0.480251\n",
      "CPU times: user 23.7 s, sys: 280 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 226.0 M\n",
      "\t Line : 22600000\t logloss: 0.482669\t batch logloss: 0.485304\n",
      "CPU times: user 23.7 s, sys: 262 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 227.0 M\n",
      "\t Line : 22700000\t logloss: 0.482672\t batch logloss: 0.483270\n",
      "CPU times: user 23.8 s, sys: 271 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 228.0 M\n",
      "\t Line : 22800000\t logloss: 0.482672\t batch logloss: 0.482744\n",
      "CPU times: user 23.8 s, sys: 275 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 229.0 M\n",
      "\t Line : 22900000\t logloss: 0.482673\t batch logloss: 0.482767\n",
      "CPU times: user 24 s, sys: 390 ms, total: 24.3 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 230.0 M\n",
      "\t Line : 23000000\t logloss: 0.482660\t batch logloss: 0.479803\n",
      "CPU times: user 23.8 s, sys: 262 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 231.0 M\n",
      "\t Line : 23100000\t logloss: 0.482628\t batch logloss: 0.475344\n",
      "CPU times: user 23.9 s, sys: 274 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 232.0 M\n",
      "\t Line : 23200000\t logloss: 0.482608\t batch logloss: 0.477802\n",
      "CPU times: user 23.7 s, sys: 263 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 233.0 M\n",
      "\t Line : 23300000\t logloss: 0.482572\t batch logloss: 0.474367\n",
      "CPU times: user 23.6 s, sys: 273 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 234.0 M\n",
      "\t Line : 23400000\t logloss: 0.482547\t batch logloss: 0.476599\n",
      "CPU times: user 23.9 s, sys: 270 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 235.0 M\n",
      "\t Line : 23500000\t logloss: 0.482526\t batch logloss: 0.477597\n",
      "CPU times: user 23.7 s, sys: 253 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 236.0 M\n",
      "\t Line : 23600000\t logloss: 0.482488\t batch logloss: 0.473575\n",
      "CPU times: user 23.7 s, sys: 267 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 237.0 M\n",
      "\t Line : 23700000\t logloss: 0.482433\t batch logloss: 0.469451\n",
      "CPU times: user 23.7 s, sys: 289 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 238.0 M\n",
      "\t Line : 23800000\t logloss: 0.482383\t batch logloss: 0.470549\n",
      "CPU times: user 23.8 s, sys: 270 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 239.0 M\n",
      "\t Line : 23900000\t logloss: 0.482341\t batch logloss: 0.472401\n",
      "CPU times: user 23.9 s, sys: 268 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 240.0 M\n",
      "\t Line : 24000000\t logloss: 0.482292\t batch logloss: 0.470562\n",
      "CPU times: user 23.7 s, sys: 261 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 241.0 M\n",
      "\t Line : 24100000\t logloss: 0.482234\t batch logloss: 0.468205\n",
      "CPU times: user 23.8 s, sys: 266 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 242.0 M\n",
      "\t Line : 24200000\t logloss: 0.482189\t batch logloss: 0.471389\n",
      "CPU times: user 24 s, sys: 402 ms, total: 24.4 s\n",
      "Wall time: 24.5 s\n",
      "\n",
      "training ... 243.0 M\n",
      "\t Line : 24300000\t logloss: 0.482141\t batch logloss: 0.470478\n",
      "CPU times: user 23.9 s, sys: 274 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 244.0 M\n",
      "\t Line : 24400000\t logloss: 0.482100\t batch logloss: 0.472357\n",
      "CPU times: user 23.8 s, sys: 282 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 245.0 M\n",
      "\t Line : 24500000\t logloss: 0.482069\t batch logloss: 0.474375\n",
      "CPU times: user 23.6 s, sys: 267 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 246.0 M\n",
      "\t Line : 24600000\t logloss: 0.482024\t batch logloss: 0.471055\n",
      "CPU times: user 23.7 s, sys: 260 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 247.0 M\n",
      "\t Line : 24700000\t logloss: 0.481971\t batch logloss: 0.469016\n",
      "CPU times: user 24 s, sys: 266 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 248.0 M\n",
      "\t Line : 24800000\t logloss: 0.481935\t batch logloss: 0.473038\n",
      "CPU times: user 24.1 s, sys: 280 ms, total: 24.4 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 249.0 M\n",
      "\t Line : 24900000\t logloss: 0.481914\t batch logloss: 0.476666\n",
      "CPU times: user 24.1 s, sys: 264 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 250.0 M\n",
      "\t Line : 25000000\t logloss: 0.481878\t batch logloss: 0.472803\n",
      "CPU times: user 23.7 s, sys: 298 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 251.0 M\n",
      "\t Line : 25100000\t logloss: 0.481843\t batch logloss: 0.473101\n",
      "CPU times: user 24.2 s, sys: 287 ms, total: 24.5 s\n",
      "Wall time: 24.5 s\n",
      "\n",
      "training ... 252.0 M\n",
      "\t Line : 25200000\t logloss: 0.481785\t batch logloss: 0.467266\n",
      "CPU times: user 24.1 s, sys: 256 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 253.0 M\n",
      "\t Line : 25300000\t logloss: 0.481741\t batch logloss: 0.470619\n",
      "CPU times: user 23.9 s, sys: 280 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 254.0 M\n",
      "\t Line : 25400000\t logloss: 0.481702\t batch logloss: 0.471958\n",
      "CPU times: user 23.8 s, sys: 274 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 255.0 M\n",
      "\t Line : 25500000\t logloss: 0.481682\t batch logloss: 0.476552\n",
      "CPU times: user 24.2 s, sys: 439 ms, total: 24.6 s\n",
      "Wall time: 24.7 s\n",
      "\n",
      "training ... 256.0 M\n",
      "\t Line : 25600000\t logloss: 0.481661\t batch logloss: 0.476346\n",
      "CPU times: user 24 s, sys: 274 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 257.0 M\n",
      "\t Line : 25700000\t logloss: 0.481619\t batch logloss: 0.470797\n",
      "CPU times: user 23.8 s, sys: 275 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 258.0 M\n",
      "\t Line : 25800000\t logloss: 0.481588\t batch logloss: 0.473593\n",
      "CPU times: user 23.7 s, sys: 275 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 259.0 M\n",
      "\t Line : 25900000\t logloss: 0.481542\t batch logloss: 0.469713\n",
      "CPU times: user 23.7 s, sys: 267 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 260.0 M\n",
      "\t Line : 26000000\t logloss: 0.481525\t batch logloss: 0.477164\n",
      "CPU times: user 24 s, sys: 573 ms, total: 24.6 s\n",
      "Wall time: 24.7 s\n",
      "\n",
      "training ... 261.0 M\n",
      "\t Line : 26100000\t logloss: 0.481489\t batch logloss: 0.472059\n",
      "CPU times: user 23.4 s, sys: 268 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 262.0 M\n",
      "\t Line : 26200000\t logloss: 0.481437\t batch logloss: 0.467873\n",
      "CPU times: user 23.5 s, sys: 302 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 263.0 M\n",
      "\t Line : 26300000\t logloss: 0.481352\t batch logloss: 0.459205\n",
      "CPU times: user 23.4 s, sys: 276 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 264.0 M\n",
      "\t Line : 26400000\t logloss: 0.481271\t batch logloss: 0.459924\n",
      "CPU times: user 23.4 s, sys: 298 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 265.0 M\n",
      "\t Line : 26500000\t logloss: 0.481282\t batch logloss: 0.484068\n",
      "CPU times: user 23.4 s, sys: 270 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 266.0 M\n",
      "\t Line : 26600000\t logloss: 0.481310\t batch logloss: 0.488652\n",
      "CPU times: user 23.5 s, sys: 258 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 267.0 M\n",
      "\t Line : 26700000\t logloss: 0.481357\t batch logloss: 0.493848\n",
      "CPU times: user 23.3 s, sys: 277 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 268.0 M\n",
      "\t Line : 26800000\t logloss: 0.481406\t batch logloss: 0.494668\n",
      "CPU times: user 23.6 s, sys: 409 ms, total: 24 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 269.0 M\n",
      "\t Line : 26900000\t logloss: 0.481443\t batch logloss: 0.491257\n",
      "CPU times: user 23.5 s, sys: 274 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 270.0 M\n",
      "\t Line : 27000000\t logloss: 0.481461\t batch logloss: 0.486317\n",
      "CPU times: user 23.4 s, sys: 255 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 271.0 M\n",
      "\t Line : 27100000\t logloss: 0.481472\t batch logloss: 0.484599\n",
      "CPU times: user 23.3 s, sys: 241 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 272.0 M\n",
      "\t Line : 27200000\t logloss: 0.481486\t batch logloss: 0.485178\n",
      "CPU times: user 23.5 s, sys: 266 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 273.0 M\n",
      "\t Line : 27300000\t logloss: 0.481479\t batch logloss: 0.479600\n",
      "CPU times: user 23.5 s, sys: 247 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 274.0 M\n",
      "\t Line : 27400000\t logloss: 0.481473\t batch logloss: 0.479842\n",
      "CPU times: user 23.4 s, sys: 263 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 275.0 M\n",
      "\t Line : 27500000\t logloss: 0.481449\t batch logloss: 0.474747\n",
      "CPU times: user 23.5 s, sys: 254 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 276.0 M\n",
      "\t Line : 27600000\t logloss: 0.481432\t batch logloss: 0.476793\n",
      "CPU times: user 23.2 s, sys: 258 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 277.0 M\n",
      "\t Line : 27700000\t logloss: 0.481425\t batch logloss: 0.479579\n",
      "CPU times: user 23.5 s, sys: 251 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 278.0 M\n",
      "\t Line : 27800000\t logloss: 0.481408\t batch logloss: 0.476643\n",
      "CPU times: user 23.4 s, sys: 259 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 279.0 M\n",
      "\t Line : 27900000\t logloss: 0.481389\t batch logloss: 0.476032\n",
      "CPU times: user 23.2 s, sys: 256 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 280.0 M\n",
      "\t Line : 28000000\t logloss: 0.481358\t batch logloss: 0.472834\n",
      "CPU times: user 23.4 s, sys: 257 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 281.0 M\n",
      "\t Line : 28100000\t logloss: 0.481341\t batch logloss: 0.476451\n",
      "CPU times: user 23.7 s, sys: 340 ms, total: 24 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 282.0 M\n",
      "\t Line : 28200000\t logloss: 0.481321\t batch logloss: 0.475732\n",
      "CPU times: user 23.5 s, sys: 266 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 283.0 M\n",
      "\t Line : 28300000\t logloss: 0.481286\t batch logloss: 0.471370\n",
      "CPU times: user 23.2 s, sys: 267 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 284.0 M\n",
      "\t Line : 28400000\t logloss: 0.481267\t batch logloss: 0.476032\n",
      "CPU times: user 23.6 s, sys: 272 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 285.0 M\n",
      "\t Line : 28500000\t logloss: 0.481259\t batch logloss: 0.478958\n",
      "CPU times: user 23.6 s, sys: 265 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 286.0 M\n",
      "\t Line : 28600000\t logloss: 0.481249\t batch logloss: 0.478345\n",
      "CPU times: user 23.3 s, sys: 254 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 287.0 M\n",
      "\t Line : 28700000\t logloss: 0.481237\t batch logloss: 0.477745\n",
      "CPU times: user 23.3 s, sys: 265 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 288.0 M\n",
      "\t Line : 28800000\t logloss: 0.481234\t batch logloss: 0.480504\n",
      "CPU times: user 23.7 s, sys: 262 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 289.0 M\n",
      "\t Line : 28900000\t logloss: 0.481226\t batch logloss: 0.478894\n",
      "CPU times: user 23.5 s, sys: 263 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 290.0 M\n",
      "\t Line : 29000000\t logloss: 0.481210\t batch logloss: 0.476505\n",
      "CPU times: user 23.5 s, sys: 248 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 291.0 M\n",
      "\t Line : 29100000\t logloss: 0.481201\t batch logloss: 0.478564\n",
      "CPU times: user 23.5 s, sys: 270 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 292.0 M\n",
      "\t Line : 29200000\t logloss: 0.481188\t batch logloss: 0.477539\n",
      "CPU times: user 23.3 s, sys: 263 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 293.0 M\n",
      "\t Line : 29300000\t logloss: 0.481177\t batch logloss: 0.478061\n",
      "CPU times: user 23.5 s, sys: 255 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 294.0 M\n",
      "\t Line : 29400000\t logloss: 0.481176\t batch logloss: 0.480667\n",
      "CPU times: user 23.5 s, sys: 255 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 295.0 M\n",
      "\t Line : 29500000\t logloss: 0.481180\t batch logloss: 0.482543\n",
      "CPU times: user 23.5 s, sys: 263 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 296.0 M\n",
      "\t Line : 29600000\t logloss: 0.481172\t batch logloss: 0.478679\n",
      "CPU times: user 23.3 s, sys: 254 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 297.0 M\n",
      "\t Line : 29700000\t logloss: 0.481170\t batch logloss: 0.480732\n",
      "CPU times: user 23.7 s, sys: 258 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 298.0 M\n",
      "\t Line : 29800000\t logloss: 0.481165\t batch logloss: 0.479476\n",
      "CPU times: user 23.4 s, sys: 262 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 299.0 M\n",
      "\t Line : 29900000\t logloss: 0.481155\t batch logloss: 0.478262\n",
      "CPU times: user 23.5 s, sys: 239 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 300.0 M\n",
      "\t Line : 30000000\t logloss: 0.481141\t batch logloss: 0.476935\n",
      "CPU times: user 23.5 s, sys: 248 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 301.0 M\n",
      "\t Line : 30100000\t logloss: 0.481127\t batch logloss: 0.476803\n",
      "CPU times: user 23.5 s, sys: 261 ms, total: 23.8 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 302.0 M\n",
      "\t Line : 30200000\t logloss: 0.481106\t batch logloss: 0.475044\n",
      "CPU times: user 23.9 s, sys: 413 ms, total: 24.3 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 303.0 M\n",
      "\t Line : 30300000\t logloss: 0.481086\t batch logloss: 0.474973\n",
      "CPU times: user 23.9 s, sys: 314 ms, total: 24.2 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 304.0 M\n",
      "\t Line : 30400000\t logloss: 0.481046\t batch logloss: 0.469018\n",
      "CPU times: user 23.5 s, sys: 247 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 305.0 M\n",
      "\t Line : 30500000\t logloss: 0.481027\t batch logloss: 0.475135\n",
      "CPU times: user 23.5 s, sys: 261 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 306.0 M\n",
      "\t Line : 30600000\t logloss: 0.481010\t batch logloss: 0.475712\n",
      "CPU times: user 23.7 s, sys: 255 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 307.0 M\n",
      "\t Line : 30700000\t logloss: 0.481000\t batch logloss: 0.477945\n",
      "CPU times: user 23.3 s, sys: 265 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 308.0 M\n",
      "\t Line : 30800000\t logloss: 0.480973\t batch logloss: 0.472860\n",
      "CPU times: user 23.7 s, sys: 283 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 309.0 M\n",
      "\t Line : 30900000\t logloss: 0.480954\t batch logloss: 0.474901\n",
      "CPU times: user 23.6 s, sys: 312 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 310.0 M\n",
      "\t Line : 31000000\t logloss: 0.480931\t batch logloss: 0.473885\n",
      "CPU times: user 23.4 s, sys: 256 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 311.0 M\n",
      "\t Line : 31100000\t logloss: 0.480909\t batch logloss: 0.474251\n",
      "CPU times: user 23.4 s, sys: 259 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 312.0 M\n",
      "\t Line : 31200000\t logloss: 0.480890\t batch logloss: 0.474924\n",
      "CPU times: user 23.5 s, sys: 259 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 313.0 M\n",
      "\t Line : 31300000\t logloss: 0.480871\t batch logloss: 0.474831\n",
      "CPU times: user 23.7 s, sys: 267 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 314.0 M\n",
      "\t Line : 31400000\t logloss: 0.480844\t batch logloss: 0.472311\n",
      "CPU times: user 23.6 s, sys: 261 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 315.0 M\n",
      "\t Line : 31500000\t logloss: 0.480802\t batch logloss: 0.467649\n",
      "CPU times: user 23.4 s, sys: 302 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 316.0 M\n",
      "\t Line : 31600000\t logloss: 0.480770\t batch logloss: 0.470688\n",
      "CPU times: user 23.3 s, sys: 243 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 317.0 M\n",
      "\t Line : 31700000\t logloss: 0.480746\t batch logloss: 0.473138\n",
      "CPU times: user 23.6 s, sys: 250 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 318.0 M\n",
      "\t Line : 31800000\t logloss: 0.480724\t batch logloss: 0.473879\n",
      "CPU times: user 23.5 s, sys: 261 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 319.0 M\n",
      "\t Line : 31900000\t logloss: 0.480691\t batch logloss: 0.470204\n",
      "CPU times: user 23.6 s, sys: 275 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 320.0 M\n",
      "\t Line : 32000000\t logloss: 0.480663\t batch logloss: 0.471830\n",
      "CPU times: user 23.5 s, sys: 254 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 321.0 M\n",
      "\t Line : 32100000\t logloss: 0.480649\t batch logloss: 0.476209\n",
      "CPU times: user 23.8 s, sys: 393 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 322.0 M\n",
      "\t Line : 32200000\t logloss: 0.480640\t batch logloss: 0.477575\n",
      "CPU times: user 23.5 s, sys: 270 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 323.0 M\n",
      "\t Line : 32300000\t logloss: 0.480615\t batch logloss: 0.472708\n",
      "CPU times: user 23.5 s, sys: 255 ms, total: 23.8 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 324.0 M\n",
      "\t Line : 32400000\t logloss: 0.480603\t batch logloss: 0.476657\n",
      "CPU times: user 23.4 s, sys: 267 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 325.0 M\n",
      "\t Line : 32500000\t logloss: 0.480600\t batch logloss: 0.479513\n",
      "CPU times: user 23.5 s, sys: 254 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 326.0 M\n",
      "\t Line : 32600000\t logloss: 0.480584\t batch logloss: 0.475331\n",
      "CPU times: user 23.6 s, sys: 263 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 327.0 M\n",
      "\t Line : 32700000\t logloss: 0.480563\t batch logloss: 0.473845\n",
      "CPU times: user 23.5 s, sys: 277 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 328.0 M\n",
      "\t Line : 32800000\t logloss: 0.480531\t batch logloss: 0.470125\n",
      "CPU times: user 23.6 s, sys: 271 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 329.0 M\n",
      "\t Line : 32900000\t logloss: 0.480493\t batch logloss: 0.467842\n",
      "CPU times: user 23.7 s, sys: 257 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 330.0 M\n",
      "\t Line : 33000000\t logloss: 0.480435\t batch logloss: 0.461534\n",
      "CPU times: user 23.5 s, sys: 261 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 331.0 M\n",
      "\t Line : 33100000\t logloss: 0.480367\t batch logloss: 0.457846\n",
      "CPU times: user 23.6 s, sys: 254 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 332.0 M\n",
      "\t Line : 33200000\t logloss: 0.480304\t batch logloss: 0.459619\n",
      "CPU times: user 23.7 s, sys: 257 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 333.0 M\n",
      "\t Line : 33300000\t logloss: 0.480330\t batch logloss: 0.488865\n",
      "CPU times: user 23.7 s, sys: 273 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 334.0 M\n",
      "\t Line : 33400000\t logloss: 0.480373\t batch logloss: 0.494596\n",
      "CPU times: user 24.1 s, sys: 402 ms, total: 24.5 s\n",
      "Wall time: 24.5 s\n",
      "\n",
      "training ... 335.0 M\n",
      "\t Line : 33500000\t logloss: 0.480430\t batch logloss: 0.499470\n",
      "CPU times: user 23.4 s, sys: 266 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 336.0 M\n",
      "\t Line : 33600000\t logloss: 0.480480\t batch logloss: 0.497230\n",
      "CPU times: user 23.3 s, sys: 252 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 337.0 M\n",
      "\t Line : 33700000\t logloss: 0.480518\t batch logloss: 0.493310\n",
      "CPU times: user 23.5 s, sys: 265 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 338.0 M\n",
      "\t Line : 33800000\t logloss: 0.480548\t batch logloss: 0.490638\n",
      "CPU times: user 23.4 s, sys: 249 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 339.0 M\n",
      "\t Line : 33900000\t logloss: 0.480563\t batch logloss: 0.485592\n",
      "CPU times: user 23.4 s, sys: 256 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 340.0 M\n",
      "\t Line : 34000000\t logloss: 0.480569\t batch logloss: 0.482655\n",
      "CPU times: user 23.4 s, sys: 255 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 341.0 M\n",
      "\t Line : 34100000\t logloss: 0.480581\t batch logloss: 0.484757\n",
      "CPU times: user 23.4 s, sys: 271 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 342.0 M\n",
      "\t Line : 34200000\t logloss: 0.480591\t batch logloss: 0.483985\n",
      "CPU times: user 23.6 s, sys: 261 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 343.0 M\n",
      "\t Line : 34300000\t logloss: 0.480597\t batch logloss: 0.482629\n",
      "CPU times: user 23.5 s, sys: 263 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 344.0 M\n",
      "\t Line : 34400000\t logloss: 0.480598\t batch logloss: 0.480946\n",
      "CPU times: user 23.7 s, sys: 247 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 345.0 M\n",
      "\t Line : 34500000\t logloss: 0.480599\t batch logloss: 0.480992\n",
      "CPU times: user 23.3 s, sys: 255 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 346.0 M\n",
      "\t Line : 34600000\t logloss: 0.480599\t batch logloss: 0.480569\n",
      "CPU times: user 23.8 s, sys: 259 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 347.0 M\n",
      "\t Line : 34700000\t logloss: 0.480589\t batch logloss: 0.477075\n",
      "CPU times: user 23.8 s, sys: 332 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 348.0 M\n",
      "\t Line : 34800000\t logloss: 0.480573\t batch logloss: 0.474905\n",
      "CPU times: user 23.5 s, sys: 259 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 349.0 M\n",
      "\t Line : 34900000\t logloss: 0.480555\t batch logloss: 0.474427\n",
      "CPU times: user 23.6 s, sys: 268 ms, total: 23.9 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 350.0 M\n",
      "\t Line : 35000000\t logloss: 0.480524\t batch logloss: 0.469563\n",
      "CPU times: user 23.4 s, sys: 262 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 351.0 M\n",
      "\t Line : 35100000\t logloss: 0.480489\t batch logloss: 0.468324\n",
      "CPU times: user 23.5 s, sys: 260 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 352.0 M\n",
      "\t Line : 35200000\t logloss: 0.480466\t batch logloss: 0.472422\n",
      "CPU times: user 23.4 s, sys: 244 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 353.0 M\n",
      "\t Line : 35300000\t logloss: 0.480440\t batch logloss: 0.471410\n",
      "CPU times: user 23.6 s, sys: 265 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 354.0 M\n",
      "\t Line : 35400000\t logloss: 0.480422\t batch logloss: 0.473824\n",
      "CPU times: user 23.5 s, sys: 273 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 355.0 M\n",
      "\t Line : 35500000\t logloss: 0.480404\t batch logloss: 0.474147\n",
      "CPU times: user 23.4 s, sys: 256 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 356.0 M\n",
      "\t Line : 35600000\t logloss: 0.480389\t batch logloss: 0.475185\n",
      "CPU times: user 23.7 s, sys: 273 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 357.0 M\n",
      "\t Line : 35700000\t logloss: 0.480384\t batch logloss: 0.478381\n",
      "CPU times: user 23.5 s, sys: 253 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 358.0 M\n",
      "\t Line : 35800000\t logloss: 0.480371\t batch logloss: 0.475992\n",
      "CPU times: user 23.5 s, sys: 265 ms, total: 23.7 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 359.0 M\n",
      "\t Line : 35900000\t logloss: 0.480365\t batch logloss: 0.478010\n",
      "CPU times: user 23.6 s, sys: 260 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 360.0 M\n",
      "\t Line : 36000000\t logloss: 0.480353\t batch logloss: 0.476082\n",
      "CPU times: user 23.8 s, sys: 367 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 361.0 M\n",
      "\t Line : 36100000\t logloss: 0.480354\t batch logloss: 0.480609\n",
      "CPU times: user 23.6 s, sys: 252 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 362.0 M\n",
      "\t Line : 36200000\t logloss: 0.480344\t batch logloss: 0.476905\n",
      "CPU times: user 23.5 s, sys: 269 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 363.0 M\n",
      "\t Line : 36300000\t logloss: 0.480338\t batch logloss: 0.478190\n",
      "CPU times: user 23.6 s, sys: 257 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 364.0 M\n",
      "\t Line : 36400000\t logloss: 0.480335\t batch logloss: 0.479358\n",
      "CPU times: user 23.6 s, sys: 256 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 365.0 M\n",
      "\t Line : 36500000\t logloss: 0.480323\t batch logloss: 0.475881\n",
      "CPU times: user 23.5 s, sys: 246 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 366.0 M\n",
      "\t Line : 36600000\t logloss: 0.480326\t batch logloss: 0.481211\n",
      "CPU times: user 23.4 s, sys: 257 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 367.0 M\n",
      "\t Line : 36700000\t logloss: 0.480317\t batch logloss: 0.477111\n",
      "CPU times: user 23.6 s, sys: 252 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 368.0 M\n",
      "\t Line : 36800000\t logloss: 0.480310\t batch logloss: 0.477691\n",
      "CPU times: user 23.9 s, sys: 260 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 369.0 M\n",
      "\t Line : 36900000\t logloss: 0.480303\t batch logloss: 0.477695\n",
      "CPU times: user 23.5 s, sys: 267 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 370.0 M\n",
      "\t Line : 37000000\t logloss: 0.480302\t batch logloss: 0.479937\n",
      "CPU times: user 24 s, sys: 269 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 371.0 M\n",
      "\t Line : 37100000\t logloss: 0.480296\t batch logloss: 0.478195\n",
      "CPU times: user 23.6 s, sys: 277 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 372.0 M\n",
      "\t Line : 37200000\t logloss: 0.480291\t batch logloss: 0.478282\n",
      "CPU times: user 24 s, sys: 268 ms, total: 24.3 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 373.0 M\n",
      "\t Line : 37300000\t logloss: 0.480280\t batch logloss: 0.476456\n",
      "CPU times: user 24.1 s, sys: 311 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 374.0 M\n",
      "\t Line : 37400000\t logloss: 0.480275\t batch logloss: 0.478314\n",
      "CPU times: user 23.4 s, sys: 253 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 375.0 M\n",
      "\t Line : 37500000\t logloss: 0.480255\t batch logloss: 0.472657\n",
      "CPU times: user 23.6 s, sys: 272 ms, total: 23.9 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 376.0 M\n",
      "\t Line : 37600000\t logloss: 0.480236\t batch logloss: 0.473260\n",
      "CPU times: user 23.5 s, sys: 261 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 377.0 M\n",
      "\t Line : 37700000\t logloss: 0.480215\t batch logloss: 0.472335\n",
      "CPU times: user 23.5 s, sys: 247 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 378.0 M\n",
      "\t Line : 37800000\t logloss: 0.480176\t batch logloss: 0.465244\n",
      "CPU times: user 23.5 s, sys: 249 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 379.0 M\n",
      "\t Line : 37900000\t logloss: 0.480125\t batch logloss: 0.460819\n",
      "CPU times: user 23.6 s, sys: 267 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 380.0 M\n",
      "\t Line : 38000000\t logloss: 0.480093\t batch logloss: 0.468033\n",
      "CPU times: user 23.4 s, sys: 263 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 381.0 M\n",
      "\t Line : 38100000\t logloss: 0.480038\t batch logloss: 0.459349\n",
      "CPU times: user 23.6 s, sys: 257 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 382.0 M\n",
      "\t Line : 38200000\t logloss: 0.479984\t batch logloss: 0.459201\n",
      "CPU times: user 23.7 s, sys: 263 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 383.0 M\n",
      "\t Line : 38300000\t logloss: 0.479931\t batch logloss: 0.459944\n",
      "CPU times: user 23.8 s, sys: 268 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 384.0 M\n",
      "\t Line : 38400000\t logloss: 0.479883\t batch logloss: 0.461412\n",
      "CPU times: user 23.5 s, sys: 245 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 385.0 M\n",
      "\t Line : 38500000\t logloss: 0.479831\t batch logloss: 0.459846\n",
      "CPU times: user 23.5 s, sys: 261 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 386.0 M\n",
      "\t Line : 38600000\t logloss: 0.479787\t batch logloss: 0.462740\n",
      "CPU times: user 23.8 s, sys: 298 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 387.0 M\n",
      "\t Line : 38700000\t logloss: 0.479739\t batch logloss: 0.461290\n",
      "CPU times: user 23.6 s, sys: 266 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 388.0 M\n",
      "\t Line : 38800000\t logloss: 0.479694\t batch logloss: 0.462210\n",
      "CPU times: user 23.6 s, sys: 260 ms, total: 23.9 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 389.0 M\n",
      "\t Line : 38900000\t logloss: 0.479652\t batch logloss: 0.463370\n",
      "CPU times: user 23.7 s, sys: 261 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 390.0 M\n",
      "\t Line : 39000000\t logloss: 0.479624\t batch logloss: 0.468712\n",
      "CPU times: user 23.7 s, sys: 263 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 391.0 M\n",
      "\t Line : 39100000\t logloss: 0.479585\t batch logloss: 0.464258\n",
      "CPU times: user 23.6 s, sys: 266 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 392.0 M\n",
      "\t Line : 39200000\t logloss: 0.479538\t batch logloss: 0.461415\n",
      "CPU times: user 23.6 s, sys: 252 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 393.0 M\n",
      "\t Line : 39300000\t logloss: 0.479488\t batch logloss: 0.459912\n",
      "CPU times: user 23.6 s, sys: 269 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 394.0 M\n",
      "\t Line : 39400000\t logloss: 0.479432\t batch logloss: 0.457291\n",
      "CPU times: user 23.8 s, sys: 255 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 395.0 M\n",
      "\t Line : 39500000\t logloss: 0.479384\t batch logloss: 0.460404\n",
      "CPU times: user 23.7 s, sys: 258 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 396.0 M\n",
      "\t Line : 39600000\t logloss: 0.479322\t batch logloss: 0.454932\n",
      "CPU times: user 23.7 s, sys: 259 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 397.0 M\n",
      "\t Line : 39700000\t logloss: 0.479263\t batch logloss: 0.455957\n",
      "CPU times: user 24 s, sys: 256 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 398.0 M\n",
      "\t Line : 39800000\t logloss: 0.479190\t batch logloss: 0.450118\n",
      "CPU times: user 23.6 s, sys: 267 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 399.0 M\n",
      "\t Line : 39900000\t logloss: 0.479221\t batch logloss: 0.491600\n",
      "CPU times: user 23.8 s, sys: 309 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 400.0 M\n",
      "\t Line : 40000000\t logloss: 0.479259\t batch logloss: 0.494440\n",
      "CPU times: user 23.6 s, sys: 266 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 401.0 M\n",
      "\t Line : 40100000\t logloss: 0.479307\t batch logloss: 0.498642\n",
      "CPU times: user 23.5 s, sys: 254 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 402.0 M\n",
      "\t Line : 40200000\t logloss: 0.479336\t batch logloss: 0.490744\n",
      "CPU times: user 23.6 s, sys: 257 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 403.0 M\n",
      "\t Line : 40300000\t logloss: 0.479361\t batch logloss: 0.489622\n",
      "CPU times: user 23.5 s, sys: 258 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 404.0 M\n",
      "\t Line : 40400000\t logloss: 0.479389\t batch logloss: 0.490546\n",
      "CPU times: user 23.2 s, sys: 256 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 405.0 M\n",
      "\t Line : 40500000\t logloss: 0.479404\t batch logloss: 0.485303\n",
      "CPU times: user 23.5 s, sys: 255 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 406.0 M\n",
      "\t Line : 40600000\t logloss: 0.479417\t batch logloss: 0.484921\n",
      "CPU times: user 23.9 s, sys: 282 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 407.0 M\n",
      "\t Line : 40700000\t logloss: 0.479435\t batch logloss: 0.486758\n",
      "CPU times: user 23.9 s, sys: 261 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 408.0 M\n",
      "\t Line : 40800000\t logloss: 0.479439\t batch logloss: 0.481074\n",
      "CPU times: user 24 s, sys: 268 ms, total: 24.3 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 409.0 M\n",
      "\t Line : 40900000\t logloss: 0.479450\t batch logloss: 0.483669\n",
      "CPU times: user 23.5 s, sys: 248 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 410.0 M\n",
      "\t Line : 41000000\t logloss: 0.479449\t batch logloss: 0.479197\n",
      "CPU times: user 23.5 s, sys: 256 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 411.0 M\n",
      "\t Line : 41100000\t logloss: 0.479441\t batch logloss: 0.476086\n",
      "CPU times: user 23.5 s, sys: 256 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 412.0 M\n",
      "\t Line : 41200000\t logloss: 0.479433\t batch logloss: 0.476086\n",
      "CPU times: user 23.4 s, sys: 265 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 413.0 M\n",
      "\t Line : 41300000\t logloss: 0.479424\t batch logloss: 0.475726\n",
      "CPU times: user 23.8 s, sys: 390 ms, total: 24.1 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 414.0 M\n",
      "\t Line : 41400000\t logloss: 0.479421\t batch logloss: 0.478356\n",
      "CPU times: user 23.4 s, sys: 243 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 415.0 M\n",
      "\t Line : 41500000\t logloss: 0.479407\t batch logloss: 0.473727\n",
      "CPU times: user 23.8 s, sys: 264 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 416.0 M\n",
      "\t Line : 41600000\t logloss: 0.479399\t batch logloss: 0.475703\n",
      "CPU times: user 23.6 s, sys: 255 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 417.0 M\n",
      "\t Line : 41700000\t logloss: 0.479385\t batch logloss: 0.473938\n",
      "CPU times: user 23.3 s, sys: 258 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 418.0 M\n",
      "\t Line : 41800000\t logloss: 0.479383\t batch logloss: 0.478567\n",
      "CPU times: user 23.5 s, sys: 261 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 419.0 M\n",
      "\t Line : 41900000\t logloss: 0.479376\t batch logloss: 0.476379\n",
      "CPU times: user 23.3 s, sys: 250 ms, total: 23.6 s\n",
      "Wall time: 23.5 s\n",
      "\n",
      "training ... 420.0 M\n",
      "\t Line : 42000000\t logloss: 0.479374\t batch logloss: 0.478557\n",
      "CPU times: user 23.6 s, sys: 262 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 421.0 M\n",
      "\t Line : 42100000\t logloss: 0.479375\t batch logloss: 0.479838\n",
      "CPU times: user 23.5 s, sys: 253 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 422.0 M\n",
      "\t Line : 42200000\t logloss: 0.479381\t batch logloss: 0.481682\n",
      "CPU times: user 23.6 s, sys: 258 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 423.0 M\n",
      "\t Line : 42300000\t logloss: 0.479390\t batch logloss: 0.483255\n",
      "CPU times: user 23.6 s, sys: 261 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 424.0 M\n",
      "\t Line : 42400000\t logloss: 0.479398\t batch logloss: 0.482663\n",
      "CPU times: user 23.5 s, sys: 258 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 425.0 M\n",
      "\t Line : 42500000\t logloss: 0.479403\t batch logloss: 0.481679\n",
      "CPU times: user 23.8 s, sys: 256 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 426.0 M\n",
      "\t Line : 42600000\t logloss: 0.479406\t batch logloss: 0.480402\n",
      "CPU times: user 23.8 s, sys: 439 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 427.0 M\n",
      "\t Line : 42700000\t logloss: 0.479404\t batch logloss: 0.478970\n",
      "CPU times: user 23.4 s, sys: 255 ms, total: 23.7 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 428.0 M\n",
      "\t Line : 42800000\t logloss: 0.479405\t batch logloss: 0.479780\n",
      "CPU times: user 23.5 s, sys: 268 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 429.0 M\n",
      "\t Line : 42900000\t logloss: 0.479401\t batch logloss: 0.477696\n",
      "CPU times: user 23.5 s, sys: 265 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 430.0 M\n",
      "\t Line : 43000000\t logloss: 0.479395\t batch logloss: 0.476737\n",
      "CPU times: user 24 s, sys: 269 ms, total: 24.2 s\n",
      "Wall time: 24.2 s\n",
      "\n",
      "training ... 431.0 M\n",
      "\t Line : 43100000\t logloss: 0.479389\t batch logloss: 0.476583\n",
      "CPU times: user 23.4 s, sys: 249 ms, total: 23.6 s\n",
      "Wall time: 23.6 s\n",
      "\n",
      "training ... 432.0 M\n",
      "\t Line : 43200000\t logloss: 0.479377\t batch logloss: 0.474533\n",
      "CPU times: user 23.5 s, sys: 253 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 433.0 M\n",
      "\t Line : 43300000\t logloss: 0.479370\t batch logloss: 0.476215\n",
      "CPU times: user 23.7 s, sys: 266 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 434.0 M\n",
      "\t Line : 43400000\t logloss: 0.479367\t batch logloss: 0.478184\n",
      "CPU times: user 23.5 s, sys: 244 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 435.0 M\n",
      "\t Line : 43500000\t logloss: 0.479363\t batch logloss: 0.477422\n",
      "CPU times: user 23.6 s, sys: 244 ms, total: 23.8 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 436.0 M\n",
      "\t Line : 43600000\t logloss: 0.479363\t batch logloss: 0.479239\n",
      "CPU times: user 23.5 s, sys: 258 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 437.0 M\n",
      "\t Line : 43700000\t logloss: 0.479365\t batch logloss: 0.480256\n",
      "CPU times: user 23.4 s, sys: 263 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 438.0 M\n",
      "\t Line : 43800000\t logloss: 0.479366\t batch logloss: 0.479938\n",
      "CPU times: user 23.5 s, sys: 273 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 439.0 M\n",
      "\t Line : 43900000\t logloss: 0.479360\t batch logloss: 0.476872\n",
      "CPU times: user 23.6 s, sys: 397 ms, total: 24 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 440.0 M\n",
      "\t Line : 44000000\t logloss: 0.479354\t batch logloss: 0.476681\n",
      "CPU times: user 23.7 s, sys: 253 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 441.0 M\n",
      "\t Line : 44100000\t logloss: 0.479347\t batch logloss: 0.476261\n",
      "CPU times: user 23.7 s, sys: 273 ms, total: 24 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 442.0 M\n",
      "\t Line : 44200000\t logloss: 0.479338\t batch logloss: 0.475059\n",
      "CPU times: user 23.6 s, sys: 264 ms, total: 23.9 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 443.0 M\n",
      "\t Line : 44300000\t logloss: 0.479328\t batch logloss: 0.474993\n",
      "CPU times: user 23.7 s, sys: 269 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 444.0 M\n",
      "\t Line : 44400000\t logloss: 0.479314\t batch logloss: 0.473058\n",
      "CPU times: user 23.5 s, sys: 241 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n",
      "\n",
      "training ... 445.0 M\n",
      "\t Line : 44500000\t logloss: 0.479312\t batch logloss: 0.478801\n",
      "CPU times: user 23.6 s, sys: 277 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 446.0 M\n",
      "\t Line : 44600000\t logloss: 0.479298\t batch logloss: 0.473038\n",
      "CPU times: user 23.8 s, sys: 259 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 447.0 M\n",
      "\t Line : 44700000\t logloss: 0.479278\t batch logloss: 0.470268\n",
      "CPU times: user 23.9 s, sys: 450 ms, total: 24.4 s\n",
      "Wall time: 24.4 s\n",
      "\n",
      "training ... 448.0 M\n",
      "\t Line : 44800000\t logloss: 0.479262\t batch logloss: 0.472202\n",
      "CPU times: user 23.6 s, sys: 247 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 449.0 M\n",
      "\t Line : 44900000\t logloss: 0.479249\t batch logloss: 0.473422\n",
      "CPU times: user 23.6 s, sys: 252 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 450.0 M\n",
      "\t Line : 45000000\t logloss: 0.479245\t batch logloss: 0.477512\n",
      "CPU times: user 23.7 s, sys: 256 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 451.0 M\n",
      "\t Line : 45100000\t logloss: 0.479242\t batch logloss: 0.477512\n",
      "CPU times: user 23.7 s, sys: 261 ms, total: 24 s\n",
      "Wall time: 24 s\n",
      "\n",
      "training ... 452.0 M\n",
      "\t Line : 45200000\t logloss: 0.479237\t batch logloss: 0.477238\n",
      "CPU times: user 23.9 s, sys: 367 ms, total: 24.2 s\n",
      "Wall time: 24.3 s\n",
      "\n",
      "training ... 453.0 M\n",
      "\t Line : 45300000\t logloss: 0.479233\t batch logloss: 0.477412\n",
      "CPU times: user 23.9 s, sys: 258 ms, total: 24.1 s\n",
      "Wall time: 24.1 s\n",
      "\n",
      "training ... 454.0 M\n",
      "\t Line : 45400000\t logloss: 0.479228\t batch logloss: 0.477016\n",
      "CPU times: user 23.6 s, sys: 262 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 455.0 M\n",
      "\t Line : 45500000\t logloss: 0.479221\t batch logloss: 0.475877\n",
      "CPU times: user 23.6 s, sys: 260 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 456.0 M\n",
      "\t Line : 45600000\t logloss: 0.479204\t batch logloss: 0.471455\n",
      "CPU times: user 23.6 s, sys: 249 ms, total: 23.9 s\n",
      "Wall time: 23.8 s\n",
      "\n",
      "training ... 457.0 M\n",
      "\t Line : 45700000\t logloss: 0.479199\t batch logloss: 0.477103\n",
      "CPU times: user 23.6 s, sys: 258 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 458.0 M\n",
      "\t Line : 45800000\t logloss: 0.479183\t batch logloss: 0.471938\n",
      "CPU times: user 23.7 s, sys: 242 ms, total: 23.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "training ... 459.0 M\n",
      "CPU times: user 9.57 s, sys: 110 ms, total: 9.68 s\n",
      "Wall time: 9.67 s\n",
      "CPU times: user 3h 15min 47s, sys: 3min 50s, total: 3h 19min 37s\n",
      "Wall time: 3h 20min 4s\n"
     ]
    }
   ],
   "source": [
    "%time weights, gradients, score_liste, t = trainAll(f, FutureEngineering=['C10', 'C7' , 'C11'], chunksize = 10 ** 5, separator='\\t', alpha=.004, batch_size=10**5, D=2**21, LoadBack=False)\n",
    "\n",
    "DumpObject(\"settings/weights\", weights)\n",
    "DumpObject(\"settings/score_liste\", score_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n"
     ]
    }
   ],
   "source": [
    "print len(score_liste[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45840618"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_loss = []\n",
    "for i in range(1,len(score_liste)):\n",
    "    score_loss.append(score_liste[i]/(i*100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlBOLmZmVlBOLmZmVlBOLmZmV1P8HwI7jCbjibGEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c38a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot([x for x in xrange(1,len(score_loss)+1)], score_loss)\n",
    "plt.title('Score Logloss')\n",
    "plt.xlabel('Training size 10**5')\n",
    "plt.ylabel('Logloss')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pour alpha = 0.004\n",
    "2016-12-29 04:59:07.563713\t Line : 500000\t logloss: 0.516549\t batch logloss: 0.516549\n",
    "2016-12-29 05:01:13.007199\t Line : 1000000\t logloss: 0.507760\t batch logloss: 0.498971\n",
    "2016-12-29 05:03:12.327480\t Line : 1500000\t logloss: 0.501969\t batch logloss: 0.490387\n",
    "2016-12-29 05:05:12.415460\t Line : 2000000\t logloss: 0.497758\t batch logloss: 0.485126\n",
    "2016-12-29 05:07:12.475359\t Line : 2500000\t logloss: 0.495029\t batch logloss: 0.484113\n",
    "2016-12-29 05:09:17.758556\t Line : 3000000\t logloss: 0.493442\t batch logloss: 0.485504\n",
    "2016-12-29 05:11:25.265730\t Line : 3500000\t logloss: 0.492467\t batch logloss: 0.486617\n",
    "                    \n",
    "pour alpha = 0.001\n",
    "2016-12-29 04:40:38.542845\t Line : 500000\t logloss: 0.549019\t batch logloss: 0.549019\n",
    "2016-12-29 04:42:38.738433\t Line : 1000000\t logloss: 0.539918\t batch logloss: 0.530816\n",
    "2016-12-29 04:44:46.764942\t Line : 1500000\t logloss: 0.533537\t batch logloss: 0.520776\n",
    "2016-12-29 04:46:44.721870\t Line : 2000000\t logloss: 0.528584\t batch logloss: 0.513725\n",
    "2016-12-29 04:48:38.084063\t Line : 2500000\t logloss: 0.525231\t batch logloss: 0.511818\n",
    "2016-12-29 04:50:35.794532\t Line : 3000000\t logloss: 0.523291\t batch logloss: 0.513592\n",
    "2016-12-29 04:52:36.770099\t Line : 3500000\t logloss: 0.521882\t batch logloss: 0.513427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lire direct : 3min 5s\n",
    "lire par chunk : 3min 50s\n",
    "lire par chunk depuis zip : 5min [+ 5min 12s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing(df, FutureEngineering, D, w, t, submission):\n",
    "    dd = {}\n",
    "    for i in range(1,14):\n",
    "        dd[i]=\"I\"+`i`   \n",
    "    for c in range(1,27):\n",
    "        dd[c+13]=\"C\"+`c`\n",
    "    \n",
    "    df.rename(columns=dd, inplace=True)\n",
    "    #cleanNull(df)\n",
    "    generateFeatureEngine(df, FutureEngineering[:3])\n",
    "    header = df.columns.values\n",
    "    df = np.array(df, dtype='str')\n",
    "    \n",
    "    for row in df:\n",
    "        # step 1, get the hashed features\n",
    "        x = get_direct_x(row, header, D)\n",
    "        # step 2, get prediction\n",
    "        p = get_prob(x, w)\n",
    "        submission.write('%d,%f\\n' % (60000000+int(t), p))\n",
    "        t+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testAll(extractfile, chunksize, FutureEngineering, D, w):\n",
    "    extractfile.seek(0)\n",
    "    # build kaggle's submission file\n",
    "    with open('submission.csv', 'w') as submission:\n",
    "        submission.write('Id,Predicted\\n')\n",
    "        t=0\n",
    "        for chunk in pd.read_csv(test, chunksize=chunksize, header=-1, sep='\\t'):\n",
    "            print \"\\ntesting ...\",`(t+chunksize)/chunksize`,\"M\"\n",
    "            %time testing(chunk, FutureEngineering, D, w, t, submission)\n",
    "            t=t+len(chunk)\n",
    "            \n",
    "        print \"\\nDone \\n\"\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing ... 1 M\n",
      "CPU times: user 17.3 s, sys: 718 ms, total: 18 s\n",
      "Wall time: 18.3 s\n",
      "\n",
      "testing ... 2 M\n",
      "CPU times: user 17.6 s, sys: 625 ms, total: 18.3 s\n",
      "Wall time: 18.6 s\n",
      "\n",
      "testing ... 3 M\n",
      "CPU times: user 15.9 s, sys: 342 ms, total: 16.3 s\n",
      "Wall time: 16.4 s\n",
      "\n",
      "testing ... 4 M\n",
      "CPU times: user 16.2 s, sys: 365 ms, total: 16.6 s\n",
      "Wall time: 16.6 s\n",
      "\n",
      "testing ... 5 M\n",
      "CPU times: user 16.4 s, sys: 379 ms, total: 16.8 s\n",
      "Wall time: 17.1 s\n",
      "\n",
      "testing ... 6 M\n",
      "CPU times: user 17.9 s, sys: 621 ms, total: 18.5 s\n",
      "Wall time: 19.2 s\n",
      "\n",
      "testing ... 7 M\n",
      "CPU times: user 18.4 s, sys: 872 ms, total: 19.3 s\n",
      "Wall time: 20 s\n",
      "\n",
      "testing ... 8 M\n",
      "CPU times: user 19.6 s, sys: 1.03 s, total: 20.7 s\n",
      "Wall time: 22.1 s\n",
      "\n",
      "testing ... 9 M\n",
      "CPU times: user 18.6 s, sys: 442 ms, total: 19 s\n",
      "Wall time: 19.2 s\n",
      "\n",
      "testing ... 10 M\n",
      "CPU times: user 18.7 s, sys: 441 ms, total: 19.2 s\n",
      "Wall time: 19.3 s\n",
      "\n",
      "testing ... 11 M\n",
      "CPU times: user 18.6 s, sys: 431 ms, total: 19.1 s\n",
      "Wall time: 19.2 s\n",
      "\n",
      "testing ... 12 M\n",
      "CPU times: user 18.8 s, sys: 456 ms, total: 19.2 s\n",
      "Wall time: 19.5 s\n",
      "\n",
      "testing ... 13 M\n",
      "CPU times: user 18.6 s, sys: 586 ms, total: 19.2 s\n",
      "Wall time: 19.4 s\n",
      "\n",
      "testing ... 14 M\n",
      "CPU times: user 18.7 s, sys: 438 ms, total: 19.2 s\n",
      "Wall time: 19.3 s\n",
      "\n",
      "testing ... 15 M\n",
      "CPU times: user 18.7 s, sys: 440 ms, total: 19.1 s\n",
      "Wall time: 19.3 s\n",
      "\n",
      "testing ... 16 M\n",
      "CPU times: user 18.6 s, sys: 443 ms, total: 19 s\n",
      "Wall time: 19.1 s\n",
      "\n",
      "testing ... 17 M\n",
      "CPU times: user 18.7 s, sys: 522 ms, total: 19.2 s\n",
      "Wall time: 19.4 s\n",
      "\n",
      "testing ... 18 M\n",
      "CPU times: user 18.6 s, sys: 430 ms, total: 19.1 s\n",
      "Wall time: 19.2 s\n",
      "\n",
      "testing ... 19 M\n",
      "CPU times: user 18.7 s, sys: 454 ms, total: 19.2 s\n",
      "Wall time: 19.3 s\n",
      "\n",
      "testing ... 20 M\n",
      "CPU times: user 18.9 s, sys: 446 ms, total: 19.3 s\n",
      "Wall time: 19.5 s\n",
      "\n",
      "testing ... 21 M\n",
      "CPU times: user 18.8 s, sys: 447 ms, total: 19.3 s\n",
      "Wall time: 19.4 s\n",
      "\n",
      "testing ... 22 M\n",
      "CPU times: user 18.7 s, sys: 438 ms, total: 19.2 s\n",
      "Wall time: 19.3 s\n",
      "\n",
      "testing ... 23 M\n",
      "CPU times: user 18.9 s, sys: 676 ms, total: 19.6 s\n",
      "Wall time: 19.7 s\n",
      "\n",
      "testing ... 24 M\n",
      "CPU times: user 19.8 s, sys: 670 ms, total: 20.5 s\n",
      "Wall time: 20.8 s\n",
      "\n",
      "testing ... 25 M\n",
      "CPU times: user 20.9 s, sys: 609 ms, total: 21.5 s\n",
      "Wall time: 21.7 s\n",
      "\n",
      "testing ... 26 M\n",
      "CPU times: user 19.2 s, sys: 663 ms, total: 19.9 s\n",
      "Wall time: 20.1 s\n",
      "\n",
      "testing ... 27 M\n",
      "CPU times: user 16 s, sys: 306 ms, total: 16.4 s\n",
      "Wall time: 16.4 s\n",
      "\n",
      "testing ... 28 M\n",
      "CPU times: user 16.2 s, sys: 312 ms, total: 16.5 s\n",
      "Wall time: 16.6 s\n",
      "\n",
      "testing ... 29 M\n",
      "CPU times: user 16 s, sys: 290 ms, total: 16.2 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 30 M\n",
      "CPU times: user 16 s, sys: 288 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 31 M\n",
      "CPU times: user 15.9 s, sys: 283 ms, total: 16.2 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 32 M\n",
      "CPU times: user 16 s, sys: 287 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 33 M\n",
      "CPU times: user 15.9 s, sys: 309 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n",
      "\n",
      "testing ... 34 M\n",
      "CPU times: user 16 s, sys: 298 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 35 M\n",
      "CPU times: user 16 s, sys: 294 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 36 M\n",
      "CPU times: user 16.6 s, sys: 503 ms, total: 17.1 s\n",
      "Wall time: 17.3 s\n",
      "\n",
      "testing ... 37 M\n",
      "CPU times: user 17.3 s, sys: 443 ms, total: 17.7 s\n",
      "Wall time: 18 s\n",
      "\n",
      "testing ... 38 M\n",
      "CPU times: user 16.7 s, sys: 430 ms, total: 17.1 s\n",
      "Wall time: 17.2 s\n",
      "\n",
      "testing ... 39 M\n",
      "CPU times: user 17.4 s, sys: 432 ms, total: 17.9 s\n",
      "Wall time: 18.1 s\n",
      "\n",
      "testing ... 40 M\n",
      "CPU times: user 16.9 s, sys: 643 ms, total: 17.5 s\n",
      "Wall time: 17.7 s\n",
      "\n",
      "testing ... 41 M\n",
      "CPU times: user 16.4 s, sys: 362 ms, total: 16.8 s\n",
      "Wall time: 16.9 s\n",
      "\n",
      "testing ... 42 M\n",
      "CPU times: user 15.7 s, sys: 267 ms, total: 16 s\n",
      "Wall time: 16 s\n",
      "\n",
      "testing ... 43 M\n",
      "CPU times: user 16 s, sys: 283 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 44 M\n",
      "CPU times: user 15.7 s, sys: 267 ms, total: 16 s\n",
      "Wall time: 16 s\n",
      "\n",
      "testing ... 45 M\n",
      "CPU times: user 16 s, sys: 263 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n",
      "\n",
      "testing ... 46 M\n",
      "CPU times: user 16 s, sys: 266 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 47 M\n",
      "CPU times: user 16.2 s, sys: 291 ms, total: 16.5 s\n",
      "Wall time: 16.6 s\n",
      "\n",
      "testing ... 48 M\n",
      "CPU times: user 16 s, sys: 266 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 49 M\n",
      "CPU times: user 15.8 s, sys: 266 ms, total: 16.1 s\n",
      "Wall time: 16.1 s\n",
      "\n",
      "testing ... 50 M\n",
      "CPU times: user 15.8 s, sys: 275 ms, total: 16.1 s\n",
      "Wall time: 16.1 s\n",
      "\n",
      "testing ... 51 M\n",
      "CPU times: user 15.8 s, sys: 275 ms, total: 16.1 s\n",
      "Wall time: 16.1 s\n",
      "\n",
      "testing ... 52 M\n",
      "CPU times: user 16 s, sys: 265 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 53 M\n",
      "CPU times: user 16 s, sys: 265 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n",
      "\n",
      "testing ... 54 M\n",
      "CPU times: user 15.8 s, sys: 269 ms, total: 16.1 s\n",
      "Wall time: 16.1 s\n",
      "\n",
      "testing ... 55 M\n",
      "CPU times: user 15.8 s, sys: 270 ms, total: 16.1 s\n",
      "Wall time: 16.1 s\n",
      "\n",
      "testing ... 56 M\n",
      "CPU times: user 16 s, sys: 270 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n",
      "\n",
      "testing ... 57 M\n",
      "CPU times: user 15.9 s, sys: 273 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n",
      "\n",
      "testing ... 58 M\n",
      "CPU times: user 16.3 s, sys: 373 ms, total: 16.6 s\n",
      "Wall time: 16.7 s\n",
      "\n",
      "testing ... 59 M\n",
      "CPU times: user 16.9 s, sys: 392 ms, total: 17.3 s\n",
      "Wall time: 17.4 s\n",
      "\n",
      "testing ... 60 M\n",
      "CPU times: user 17.4 s, sys: 593 ms, total: 18 s\n",
      "Wall time: 18.3 s\n",
      "\n",
      "testing ... 61 M\n",
      "CPU times: user 6.7 s, sys: 117 ms, total: 6.82 s\n",
      "Wall time: 6.82 s\n",
      "\n",
      "Done \n",
      "\n",
      "CPU times: user 18min 35s, sys: 32.8 s, total: 19min 7s\n",
      "Wall time: 19min 19s\n"
     ]
    }
   ],
   "source": [
    "#Ramah \t0.65993 \t- \tTue, 03 Jan 2017 07:50:53 \n",
    "test = tar.extractfile('test.txt')\n",
    "%time testAll(test, chunksize=10**5, FutureEngineering=['C10', 'C7' , 'C11'], D=2**21, w=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing ... 1 M\n",
      "CPU times: user 14.9 s, sys: 554 ms, total: 15.5 s\n",
      "Wall time: 15.9 s\n",
      "\n",
      "testing ... 2 M\n",
      "CPU times: user 15 s, sys: 481 ms, total: 15.5 s\n",
      "Wall time: 16.5 s\n",
      "\n",
      "testing ... 3 M\n",
      "CPU times: user 15.1 s, sys: 385 ms, total: 15.4 s\n",
      "Wall time: 15.6 s\n",
      "\n",
      "testing ... 4 M\n",
      "CPU times: user 14.3 s, sys: 298 ms, total: 14.6 s\n",
      "Wall time: 14.7 s\n",
      "\n",
      "testing ... 5 M\n",
      "CPU times: user 14.5 s, sys: 310 ms, total: 14.8 s\n",
      "Wall time: 14.9 s\n",
      "\n",
      "testing ... 6 M\n",
      "CPU times: user 14.4 s, sys: 306 ms, total: 14.7 s\n",
      "Wall time: 14.8 s\n",
      "\n",
      "testing ... 7 M\n",
      "CPU times: user 14.2 s, sys: 296 ms, total: 14.5 s\n",
      "Wall time: 14.6 s\n",
      "\n",
      "testing ... 8 M\n",
      "CPU times: user 14.3 s, sys: 294 ms, total: 14.6 s\n",
      "Wall time: 14.6 s\n",
      "\n",
      "testing ... 9 M\n",
      "CPU times: user 14.4 s, sys: 299 ms, total: 14.7 s\n",
      "Wall time: 14.8 s\n",
      "\n",
      "testing ... 10 M\n",
      "CPU times: user 14.5 s, sys: 306 ms, total: 14.8 s\n",
      "Wall time: 14.9 s\n",
      "\n",
      "testing ... 11 M\n",
      "CPU times: user 14.4 s, sys: 302 ms, total: 14.7 s\n",
      "Wall time: 14.8 s\n",
      "\n",
      "testing ... 12 M\n",
      "CPU times: user 14.5 s, sys: 451 ms, total: 15 s\n",
      "Wall time: 15.1 s\n",
      "\n",
      "testing ... 13 M\n",
      "CPU times: user 14.4 s, sys: 299 ms, total: 14.7 s\n",
      "Wall time: 14.7 s\n",
      "\n",
      "testing ... 14 M\n",
      "CPU times: user 14.4 s, sys: 290 ms, total: 14.7 s\n",
      "Wall time: 14.8 s\n",
      "\n",
      "testing ... 15 M\n",
      "CPU times: user 14.5 s, sys: 303 ms, total: 14.8 s\n",
      "Wall time: 14.9 s\n",
      "\n",
      "testing ... 16 M\n",
      "CPU times: user 14.5 s, sys: 302 ms, total: 14.8 s\n",
      "Wall time: 14.9 s\n",
      "\n",
      "testing ... 17 M\n",
      "CPU times: user 14.5 s, sys: 301 ms, total: 14.8 s\n",
      "Wall time: 14.9 s\n",
      "\n",
      "testing ... 18 M\n",
      "CPU times: user 14.4 s, sys: 293 ms, total: 14.7 s\n",
      "Wall time: 14.8 s\n",
      "\n",
      "testing ... 19 M\n",
      "CPU times: user 14.6 s, sys: 369 ms, total: 15 s\n",
      "Wall time: 15.1 s\n",
      "\n",
      "testing ... 20 M\n",
      "CPU times: user 16.1 s, sys: 679 ms, total: 16.8 s\n",
      "Wall time: 17 s\n",
      "\n",
      "testing ... 21 M\n",
      "CPU times: user 15.9 s, sys: 432 ms, total: 16.3 s\n",
      "Wall time: 16.6 s\n",
      "\n",
      "testing ... 22 M\n",
      "CPU times: user 15.4 s, sys: 379 ms, total: 15.7 s\n",
      "Wall time: 15.8 s\n",
      "\n",
      "testing ... 23 M\n",
      "CPU times: user 12.5 s, sys: 199 ms, total: 12.7 s\n",
      "Wall time: 12.8 s\n",
      "\n",
      "testing ... 24 M\n",
      "CPU times: user 12.8 s, sys: 235 ms, total: 13 s\n",
      "Wall time: 13.1 s\n",
      "\n",
      "testing ... 25 M\n",
      "CPU times: user 13.3 s, sys: 267 ms, total: 13.5 s\n",
      "Wall time: 13.6 s\n",
      "\n",
      "testing ... 26 M\n",
      "CPU times: user 13.5 s, sys: 265 ms, total: 13.7 s\n",
      "Wall time: 13.8 s\n",
      "\n",
      "testing ... 27 M\n",
      "CPU times: user 12.7 s, sys: 203 ms, total: 12.9 s\n",
      "Wall time: 13 s\n",
      "\n",
      "testing ... 28 M\n",
      "CPU times: user 13.8 s, sys: 321 ms, total: 14.1 s\n",
      "Wall time: 14.2 s\n",
      "\n",
      "testing ... 29 M\n",
      "CPU times: user 13.8 s, sys: 297 ms, total: 14.1 s\n",
      "Wall time: 14.3 s\n",
      "\n",
      "testing ... 30 M\n",
      "CPU times: user 13.9 s, sys: 279 ms, total: 14.1 s\n",
      "Wall time: 14.2 s\n",
      "\n",
      "testing ... 31 M\n",
      "CPU times: user 12.8 s, sys: 204 ms, total: 13 s\n",
      "Wall time: 13.1 s\n",
      "\n",
      "testing ... 32 M\n",
      "CPU times: user 13.2 s, sys: 328 ms, total: 13.6 s\n",
      "Wall time: 13.7 s\n",
      "\n",
      "testing ... 33 M\n",
      "CPU times: user 12.9 s, sys: 247 ms, total: 13.2 s\n",
      "Wall time: 13.4 s\n",
      "\n",
      "testing ... 34 M\n",
      "CPU times: user 13 s, sys: 264 ms, total: 13.3 s\n",
      "Wall time: 13.4 s\n",
      "\n",
      "testing ... 35 M\n",
      "CPU times: user 12.7 s, sys: 214 ms, total: 12.9 s\n",
      "Wall time: 13 s\n",
      "\n",
      "testing ... 36 M\n",
      "CPU times: user 12.7 s, sys: 203 ms, total: 12.9 s\n",
      "Wall time: 12.9 s\n",
      "\n",
      "testing ... 37 M\n",
      "CPU times: user 12.6 s, sys: 194 ms, total: 12.8 s\n",
      "Wall time: 12.9 s\n",
      "\n",
      "testing ... 38 M\n",
      "CPU times: user 12.4 s, sys: 176 ms, total: 12.6 s\n",
      "Wall time: 12.6 s\n",
      "\n",
      "testing ... 39 M\n",
      "CPU times: user 12.5 s, sys: 199 ms, total: 12.7 s\n",
      "Wall time: 12.7 s\n",
      "\n",
      "testing ... 40 M\n",
      "CPU times: user 12.8 s, sys: 224 ms, total: 13 s\n",
      "Wall time: 13.1 s\n",
      "\n",
      "testing ... 41 M\n",
      "CPU times: user 12.8 s, sys: 246 ms, total: 13.1 s\n",
      "Wall time: 13.2 s\n",
      "\n",
      "testing ... 42 M\n",
      "CPU times: user 12.7 s, sys: 213 ms, total: 12.9 s\n",
      "Wall time: 13 s\n",
      "\n",
      "testing ... 43 M\n",
      "CPU times: user 12.5 s, sys: 211 ms, total: 12.7 s\n",
      "Wall time: 12.7 s\n",
      "\n",
      "testing ... 44 M\n",
      "CPU times: user 11.8 s, sys: 174 ms, total: 11.9 s\n",
      "Wall time: 12 s\n",
      "\n",
      "testing ... 45 M\n",
      "CPU times: user 11.7 s, sys: 185 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n",
      "\n",
      "testing ... 46 M\n",
      "CPU times: user 11.8 s, sys: 187 ms, total: 12 s\n",
      "Wall time: 12 s\n",
      "\n",
      "testing ... 47 M\n",
      "CPU times: user 11.8 s, sys: 190 ms, total: 12 s\n",
      "Wall time: 12 s\n",
      "\n",
      "testing ... 48 M\n",
      "CPU times: user 11.7 s, sys: 173 ms, total: 11.8 s\n",
      "Wall time: 11.8 s\n",
      "\n",
      "testing ... 49 M\n",
      "CPU times: user 11.7 s, sys: 176 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n",
      "\n",
      "testing ... 50 M\n",
      "CPU times: user 11.8 s, sys: 180 ms, total: 12 s\n",
      "Wall time: 12 s\n",
      "\n",
      "testing ... 51 M\n",
      "CPU times: user 11.7 s, sys: 172 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n",
      "\n",
      "testing ... 52 M\n",
      "CPU times: user 11.8 s, sys: 185 ms, total: 12 s\n",
      "Wall time: 12 s\n",
      "\n",
      "testing ... 53 M\n",
      "CPU times: user 11.7 s, sys: 173 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n",
      "\n",
      "testing ... 54 M\n",
      "CPU times: user 12.1 s, sys: 304 ms, total: 12.4 s\n",
      "Wall time: 12.4 s\n",
      "\n",
      "testing ... 55 M\n",
      "CPU times: user 11.8 s, sys: 193 ms, total: 12 s\n",
      "Wall time: 12 s\n",
      "\n",
      "testing ... 56 M\n",
      "CPU times: user 11.8 s, sys: 202 ms, total: 12 s\n",
      "Wall time: 12 s\n",
      "\n",
      "testing ... 57 M\n",
      "CPU times: user 11.8 s, sys: 178 ms, total: 12 s\n",
      "Wall time: 12 s\n",
      "\n",
      "testing ... 58 M\n",
      "CPU times: user 11.7 s, sys: 183 ms, total: 11.8 s\n",
      "Wall time: 11.8 s\n",
      "\n",
      "testing ... 59 M\n",
      "CPU times: user 11.9 s, sys: 190 ms, total: 12.1 s\n",
      "Wall time: 12.1 s\n",
      "\n",
      "testing ... 60 M\n",
      "CPU times: user 11.7 s, sys: 191 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n",
      "\n",
      "testing ... 61 M\n",
      "CPU times: user 5.31 s, sys: 96 ms, total: 5.41 s\n",
      "Wall time: 5.43 s\n",
      "\n",
      "Done \n",
      "\n",
      "CPU times: user 14min 38s, sys: 22 s, total: 15min\n",
      "Wall time: 15min 8s\n"
     ]
    }
   ],
   "source": [
    "weights = LoadObject(\"settings/search/weights_0.004_2097152_4000000\")\n",
    "test = tar.extractfile('test.txt')\n",
    "%time testAll(test, chunksize=10**5, FutureEngineering=[], D=2**21, w=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# testing (build kaggle's submission file)\n",
    "with open('submission.csv', 'w') as submission:\n",
    "    submission.write('Id,Predicted\\n')\n",
    "    for t, row in enumerate(DictReader(open(\"test.csv\"), header[1:], delimiter=',')):\n",
    "        x = get_x(row, D)\n",
    "        p = get_p(x, w)\n",
    "        submission.write('%d,%f\\n' % (60000000+int(t), p))\n",
    "%time print \"Done\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
