{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import murmurhash3_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanNull(DF):\n",
    "    for column in DF.columns.values:\n",
    "        replace = DF[column].value_counts()\n",
    "        index_min = np.argmin(replace)\n",
    "        DF[column].fillna(index_min , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateFeatureEngine(DF , toGenerate):\n",
    "    for g in toGenerate :\n",
    "        for i in toGenerate :\n",
    "            if i != g :\n",
    "                newName = str(g) + \":\" + str(i)\n",
    "                DF[newName] = newName+DF[i].astype('str')+\":\"+DF[g].astype('str')\n",
    "                print newName\n",
    "                for j in toGenerate :\n",
    "                    if j!= i and j!=g :\n",
    "                        newX = newName + \":\" + str(j)\n",
    "                        DF[newName] = newName+DF[newName]+\":\"+DF[j].astype('str')\n",
    "                        print newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF = pd.read_csv(\"4train.txt\", header=-1, sep='\\t')\n",
    "DF = pd.DataFrame(DF)\n",
    "num_Cols=[]\n",
    "cat_Cols = []\n",
    "dd = {}\n",
    "dd[0]=\"Label\"\n",
    "for i in range(1,14):\n",
    "    dd[i]=\"I\"+`i`\n",
    "    num_Cols.append(\"I\"+`i`)\n",
    "for c in range(1,27):\n",
    "    dd[c+13]=\"C\"+`c`\n",
    "    cat_Cols.append(\"C\"+`c`)\n",
    "DF.rename(columns=dd, inplace=True)\n",
    "cleanNull(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C10:C7\n",
      "C10:C7:C10\n",
      "C10:C7:C11\n",
      "C10:C11\n",
      "C10:C11:C10\n",
      "C10:C11:C7\n",
      "C7:C10\n",
      "C7:C10:C7\n",
      "C7:C10:C11\n",
      "C7:C11\n",
      "C7:C11:C10\n",
      "C7:C11:C7\n",
      "C11:C10\n",
      "C11:C10:C7\n",
      "C11:C10:C11\n",
      "C11:C7\n",
      "C11:C7:C10\n",
      "C11:C7:C11\n"
     ]
    }
   ],
   "source": [
    "TOGEN = ['C10', 'C7' , 'C11']\n",
    "generateFeatureEngine(DF,TOGEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF.to_csv(\"FinalCri.csv\" , header = False , index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Li = ['C10:C7' ,  'C10:C11' ,  'C7:C10' , 'C7:C11','C11:C10' ,'C11:C7','C11:C7:C10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          3.352366e+36\n",
       "1          6.543753e+31\n",
       "2          6.691298e+35\n",
       "3          1.937738e+36\n",
       "4          1.048944e+35\n",
       "5          6.522322e+36\n",
       "6          5.498504e+36\n",
       "7          2.846101e+35\n",
       "8          4.119412e+35\n",
       "9          6.776150e+36\n",
       "10         4.319599e+35\n",
       "11         3.194021e+35\n",
       "12         3.634647e+36\n",
       "13         6.613090e+36\n",
       "14         3.785193e+32\n",
       "15         1.580056e+36\n",
       "16         5.687776e+35\n",
       "17         1.121520e+36\n",
       "18         9.484392e+36\n",
       "19         3.958188e+36\n",
       "20         1.054987e+37\n",
       "21         1.911157e+36\n",
       "22         1.663430e+36\n",
       "23         1.445988e+36\n",
       "24         2.782370e+36\n",
       "25         7.905569e+36\n",
       "26         2.274124e+35\n",
       "27         4.666368e+36\n",
       "28         2.531238e+35\n",
       "29         4.930420e+36\n",
       "               ...     \n",
       "1999970    8.155001e+34\n",
       "1999971    9.228981e+36\n",
       "1999972    2.302909e+36\n",
       "1999973    8.928122e+35\n",
       "1999974    1.589065e+33\n",
       "1999975    4.571373e+36\n",
       "1999976    4.727051e+36\n",
       "1999977    6.716049e+36\n",
       "1999978    1.224976e+36\n",
       "1999979    3.971669e+34\n",
       "1999980    6.265337e+36\n",
       "1999981    3.773904e+35\n",
       "1999982    7.609736e+36\n",
       "1999983    1.721439e+36\n",
       "1999984    7.296648e+36\n",
       "1999985    1.633049e+36\n",
       "1999986    4.135496e+36\n",
       "1999987    3.390320e+36\n",
       "1999988    4.487535e+34\n",
       "1999989    1.547368e+36\n",
       "1999990    2.897580e+36\n",
       "1999991    8.479355e+36\n",
       "1999992    4.636665e+36\n",
       "1999993    2.452541e+36\n",
       "1999994    4.614418e+35\n",
       "1999995    1.771087e+35\n",
       "1999996    1.004606e+37\n",
       "1999997    2.669573e+35\n",
       "1999998    2.471948e+36\n",
       "1999999    1.854733e+36\n",
       "Name: C11:C7, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['C11:C7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "from sklearn.utils import murmurhash3_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = \"FinalCri.csv\"\n",
    "header = [\"Label\"]\n",
    "header = header+num_Cols+cat_Cols+Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-17), 10e-17)        # The bounds\n",
    "    return -log(p) if y == 1. else -log(1. - p)\n",
    "def get_x(csv_row, D):\n",
    "    fullind = []\n",
    "    x = {}\n",
    "    num = {}\n",
    "    for key, value in csv_row.items():\n",
    "        if key in cat_Cols:\n",
    "            s = key + ' ' + value\n",
    "            fullind.append(murmurhash3_32(s, positive=True) % D)\n",
    "        else:\n",
    "            num[key]=value\n",
    "        \n",
    "    \n",
    "    x[0] = 1  # 0 is the index of the bias term\n",
    "    for index in fullind:\n",
    "        if(not x.has_key(index)):\n",
    "            x[index] = 0\n",
    "        x[index] += 1\n",
    "    \n",
    "    return x, num  # x contains indices of features that have a value as number of occurences\n",
    "\n",
    "def get_p(x, num, w, D):\n",
    "    wTx = 0.\n",
    "    for i, xi in x.items():\n",
    "        wTx += w[i] * xi  # w[i] * x[i]\n",
    "    for numj in num.values():\n",
    "        \n",
    "        wTx += w[murmurhash3_32(''+numj, positive=True) % D] * float(numj)\n",
    "        \n",
    "        \n",
    "    return 1. / (1. + exp(-max(min(wTx, 50.), -50.)))  # bounded sigmoid\n",
    "\n",
    "def update_w(w, g, x, num, D, p, y):\n",
    "    for i, xi in x.items():\n",
    "        g[i] += 1\n",
    "        w[i] -= (p - y) * xi * alpha / (sqrt(g[i]))  # Minimising log loss\n",
    "    for numj in num.values():\n",
    "        numi = murmurhash3_32(''+numj, positive=True) % D\n",
    "        g[numi] += 1\n",
    "        w[numi] -= (p - y) * float(numj) * alpha / (sqrt(g[numi]))  # Minimising log loss\n",
    "    return w, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C10:C7:C11': 'C7:C10', 'C11:C10:C7': None, 'C7:C10:C7': None, 'C7:C11:C7': None, 'C19': 'C19', 'C18': 'C18', 'C13': 'C13', 'C12': 'C12', 'C11': 'C11', 'C10': 'C10', 'C17': 'C17', 'C16': 'C16', 'C15': 'C15', 'C14': 'C14', 'I9': 'I9', 'I8': 'I8', 'I1': 'I1', 'I3': 'I3', 'I2': 'I2', 'I5': 'I5', 'I4': 'I4', 'I7': 'I7', 'I6': 'I6', 'C9': 'C9', 'C8': 'C8', 'C10:C11:C10': 'C11:C10', 'C3': 'C3', 'C2': 'C2', 'C1': 'C1', 'C7:C11': None, 'C7': 'C7', 'C6': 'C6', 'C5': 'C5', 'C4': 'C4', 'C22': 'C22', 'C23': 'C23', 'C20': 'C20', 'C21': 'C21', 'C26': 'C26', 'C24': 'C24', 'C25': 'C25', 'I11': 'I11', 'I10': 'I10', 'I13': 'I13', 'I12': 'I12', 'C7:C10:C11': None, 'C10:C7': 'C10:C7', 'C11:C10:C11': None, 'C10:C11': 'C7:C11', 'C10:C7:C10': 'C10:C11', 'C11:C7': None, 'C11:C7:C11': None, 'C11:C7:C10': None, 'C11:C10': None, 'C7:C11:C10': None, 'C7:C10': None, 'C10:C11:C7': 'C11:C7'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate 'str' and 'NoneType' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-02ec66045c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# step 2, get prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# for progress validation, useless for learning our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-8b21109520bf>\u001b[0m in \u001b[0;36mget_p\u001b[0;34m(x, num, w, D)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnumj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mwTx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnumj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate 'str' and 'NoneType' objects"
     ]
    }
   ],
   "source": [
    "logbatch = 100000\n",
    "\n",
    "D = 2 ** 4    # number of weights use for learning\n",
    "alpha = .004  # learning rate for sgd optimization\n",
    "\n",
    "w = [0.] * D  # weights\n",
    "g = [.5] * D  # sum of historical gradients\n",
    "\n",
    "# start training a logistic regression model using on pass sgd\n",
    "loss = 0.\n",
    "lossb = 0.\n",
    "\n",
    "for t, row in enumerate(DictReader(open(train),header, delimiter=',')):\n",
    "    y = 1. if row['Label'] == '1' else 0.\n",
    "\n",
    "    del row['Label']  # can't let the model peek the answer\n",
    "\n",
    "    # main training procedure\n",
    "    # step 1, get the hashed features\n",
    "    print row\n",
    "    x, num = get_x(row, D)\n",
    "    # step 2, get prediction\n",
    "    p = get_p(x, num, w, D)\n",
    "\n",
    "    # for progress validation, useless for learning our model\n",
    "    lossx = logloss(p, y)\n",
    "    loss += lossx\n",
    "    lossb += lossx\n",
    "    if t % logbatch == 0 and t > 1:\n",
    "        print('%s\\t Line : %d\\t logloss: %f\\t batch logloss: %f' % (datetime.now(), t, loss/t, lossb/logbatch))\n",
    "        lossb = 0.\n",
    "\n",
    "    # step 3, update model with answer\n",
    "    w, g = update_w(w, g, x, num, D, p, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
